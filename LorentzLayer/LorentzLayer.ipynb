{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4]\n",
      "[3 3]\n",
      "[[ 2.]\n",
      " [ 2.]\n",
      " [ 2.]]\n",
      "[[[-5.19615173  1.99999988  1.99999988  1.99999988]]]\n",
      "[1 3 4]\n",
      "[3 3]\n",
      "[[ 2.00000048]\n",
      " [ 2.00000048]\n",
      " [ 2.00000048]]\n",
      "[[[-3.67423534  1.          3.50000072  2.50000048]]]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "from keras.engine.topology import Layer\n",
    "import theano\n",
    "import numpy as np\n",
    "from theano.compile.nanguardmode import NanGuardMode\n",
    "\n",
    "#Build K matricies\n",
    "np_K = np.zeros((3,4,4))\n",
    "for i in range(0,3):\n",
    "    np_K[i,0,i+1] = 1\n",
    "    np_K[i,i+1,0] = 1\n",
    "    \n",
    "_K = K.variable(np_K)\n",
    "\n",
    "\n",
    "def _lorentz(x, boosts,weights=None, sphereCoords=False):\n",
    "    \n",
    "    #Initialize Helpful variables\n",
    "    x_shape = K.shape(x)\n",
    "    batch_size = x_shape[0]\n",
    "    vector_cluster_size = x_shape[1]\n",
    "    _bI = K.repeat_elements(K.reshape(K.eye(4), (1,4,4)), vector_cluster_size, axis=0)\n",
    "    _b1 = K.repeat_elements(K.eye(1),vector_cluster_size, axis=0)\n",
    "    \n",
    "    #Get _mag and _n from boost which can be formatted in either\n",
    "    # Cartesian or Spherical coordinates\n",
    "    if(sphereCoords):\n",
    "        #split up the boost by components. dtype='int64' is to cast to a theano.tensor.lvector\n",
    "        _splits =K.variable([1,1,1], dtype='int64') #theano.tensor.lvector([1,1,1])\n",
    "        _theta, _phi,_mag = theano.tensor.split(boosts,_splits, 3, axis=1)\n",
    "        _theta = _theta * np.pi\n",
    "        _phi = _phi * (2 * np.pi)\n",
    "        _nx = K.sin(_theta) * K.cos(_phi) \n",
    "        _ny = K.sin(_theta) * K.sin(_phi)\n",
    "        _nz = K.cos(_theta)\n",
    "        _n = K.concatenate([_nx, _ny, _nz], axis=1)\n",
    "    else:\n",
    "        _mag = K.sqrt(K.sum(K.square(boosts), axis=1,keepdims=True))\n",
    "        _inv_mag = 1/_mag\n",
    "        _n = boosts *  _inv_mag\n",
    "    \n",
    "    #Calculate the Lorentz factor of the boost\n",
    "    _sqrMag = K.square(_mag)\n",
    "    _g = 1/K.sqrt((1.-_sqrMag))\n",
    "    print(K.eval(_g))\n",
    "    \n",
    "    #Repeat the K tensor b=vector_cluster_size times \n",
    "    _bK = K.reshape(_K, (1,3,4,4))\n",
    "    _bK = K.repeat_elements(_bK, vector_cluster_size, axis=0)\n",
    "    #Dot K with n for each cluster vector to get _nk = Bxnx + Byny + Bznz\n",
    "    _nK = K.batch_dot(_n, _bK, axes=[[1],[1]])\n",
    "    #Reshape _nk so that we can batch dot it along the [1] axis\n",
    "    _nK = K.reshape(_nK, (vector_cluster_size,1,4,4))\n",
    "    #Square _nK and reshape it correctly for each cluster vector\n",
    "    _nK2 = K.reshape(K.batch_dot(_nK,_nK), (vector_cluster_size,1,4,4))\n",
    "    #Calculate the boost matrix\n",
    "    _B = _bI - K.batch_dot(_g*_mag, _nK, axes=[[1],[1]]) +K.batch_dot(_g-_b1,_nK2,axes=[[1],[1]])\n",
    "    \n",
    "    #Apply trained weights to each Boost in the cluster\n",
    "    if(weights != None):\n",
    "        _B = K.reshape(_B, (vector_cluster_size,1,4,4))\n",
    "        weights = K.reshape(weights, (vector_cluster_size,1,1,1))\n",
    "        _B = K.batch_dot(weights, _B, axes=[[1],[1]])\n",
    "    \n",
    "    \n",
    "    #Reshape x and _B so we can dot them along the cluster axis\n",
    "    x = K.reshape(x, (batch_size, vector_cluster_size, 1, 4))\n",
    "    _B = K.reshape(_B, (1,vector_cluster_size,4,4))\n",
    "    _mB = K.repeat_elements(_B,batch_size, axis=0)\n",
    "    \n",
    "    #Dot x and _B along the cluster axis to give the summed result of the boosted vectors\n",
    "    out = K.reshape(K.batch_dot(_mB, x, axes=[[1,3],[1,3]]), (batch_size, 1,4))\n",
    "    \n",
    "    return out\n",
    "\n",
    "beta = np.sqrt(.75)\n",
    "inp = K.variable(np.array([[[0, 1, 0, 0],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]]]))\n",
    "b = K.variable(np.array([  [beta, 0, 0],\n",
    "                            [0, beta, 0],\n",
    "                            [0, 0, beta]]))\n",
    "print(K.eval(K.shape(inp)))\n",
    "print(K.eval(K.shape(b)))\n",
    "o = _lorentz(inp, b)\n",
    "#print(K.eval(_g))\n",
    "print(K.eval(o))\n",
    "\n",
    "beta = np.sqrt(3./8.)\n",
    "inp = K.variable(np.array([[[0, 1, 0, 0],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 1, 1]]]))\n",
    "b = K.variable(np.array([[0, beta, beta],\n",
    "                         [0, beta, beta],\n",
    "                         [0, beta, beta]]))\n",
    "                           \n",
    "print(K.eval(K.shape(inp)))\n",
    "print(K.eval(K.shape(b)))\n",
    "o = _lorentz(inp, b)\n",
    "#print(K.eval(_g))\n",
    "print(K.eval(o))\n",
    "\n",
    "\n",
    "class LorentzLayer(Layer):\n",
    "    def __init__(self, cluster_size, sphereCoords=False, **kwargs):\n",
    "        self.output_dim = 4\n",
    "        self.sphereCoords = sphereCoords\n",
    "        kwargs['input_shape'] = (cluster_size, 4)\n",
    "        super(LorentzLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        #The cluster size\n",
    "        input_dim = input_shape[1]\n",
    "        \n",
    "        #Boosts for each vector in the cluster\n",
    "        initial_boosts_value = np.random.random((input_dim,3))\n",
    "        #Bias Boost for the vector sum\n",
    "        initial_bias_value = np.random.random((1,3))\n",
    "        #Weight values for each vector in the cluster\n",
    "        initial_weights_value = np.random.random((input_dim,1))\n",
    "        \n",
    "        #If in Cartesian Coordinates scale so maxNorm = 1\n",
    "        if(~self.sphereCoords):\n",
    "            initial_boosts_value *= .33\n",
    "            initial_bias_value *= .33\n",
    "        \n",
    "        #store weights\n",
    "        self.Bo = K.variable(initial_boosts_value)\n",
    "        self.Bi = K.variable(initial_bias_value)\n",
    "        self.W = K.variable(initial_weights_value)\n",
    "        \n",
    "        #If in Cartesian Coordinates apply maxnorm constraint so that we can\n",
    "        #only boost our vectors into real reference frames\n",
    "        if(~self.sphereCoords):\n",
    "            self.constraints[self.Bo] = maxnorm(axis=1)\n",
    "            self.constraints[self.Bi] = maxnorm(axis=1)\n",
    "        \n",
    "        #Let keras know about our weights\n",
    "        self.trainable_weights = [self.W, self.Bi, self.Bo]\n",
    "\n",
    "    def call(self, T, mask=None):\n",
    "        #T dimensions are (batch_size, cluster_size, 4)\n",
    "        #lorentzboost of the vectorial sum of each lorentzboosted 4 vector in the cluster\n",
    "        summed_boosted = _lorentz( T, self.Bo, weights=self.W, sphereCoords=self.sphereCoords)\n",
    "        out = _lorentz(summed_boosted, self.Bi, sphereCoords=self.sphereCoords)\n",
    "        return out\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load compile.py\n",
    "#Compile\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "model = Sequential()\n",
    "model.add(LorentzLayer(12, sphereCoords=True))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train =  np.random.random((1000, 12, 4))\n",
    "y_train =  np.random.random((1000, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "0s - loss: 2.8189 - acc: 0.2490\n",
      "Epoch 2/100\n",
      "0s - loss: 1.4319 - acc: 0.2504\n",
      "Epoch 3/100\n",
      "0s - loss: 0.8346 - acc: 0.2514\n",
      "Epoch 4/100\n",
      "0s - loss: 0.5334 - acc: 0.2516\n",
      "Epoch 5/100\n",
      "0s - loss: 0.3778 - acc: 0.2503\n",
      "Epoch 6/100\n",
      "0s - loss: 0.2964 - acc: 0.2478\n",
      "Epoch 7/100\n",
      "0s - loss: 0.2514 - acc: 0.2491\n",
      "Epoch 8/100\n",
      "0s - loss: 0.2248 - acc: 0.2523\n",
      "Epoch 9/100\n",
      "0s - loss: 0.2090 - acc: 0.2498\n",
      "Epoch 10/100\n",
      "0s - loss: 0.1970 - acc: 0.2497\n",
      "Epoch 11/100\n",
      "0s - loss: 0.1884 - acc: 0.2495\n",
      "Epoch 12/100\n",
      "0s - loss: 0.1814 - acc: 0.2513\n",
      "Epoch 13/100\n",
      "0s - loss: 0.1757 - acc: 0.2503\n",
      "Epoch 14/100\n",
      "0s - loss: 0.1704 - acc: 0.2509\n",
      "Epoch 15/100\n",
      "0s - loss: 0.1656 - acc: 0.2504\n",
      "Epoch 16/100\n",
      "0s - loss: 0.1614 - acc: 0.2506\n",
      "Epoch 17/100\n",
      "0s - loss: 0.1576 - acc: 0.2513\n",
      "Epoch 18/100\n",
      "0s - loss: 0.1547 - acc: 0.2508\n",
      "Epoch 19/100\n",
      "0s - loss: 0.1511 - acc: 0.2510\n",
      "Epoch 20/100\n",
      "0s - loss: 0.1481 - acc: 0.2511\n",
      "Epoch 21/100\n",
      "0s - loss: 0.1456 - acc: 0.2536\n",
      "Epoch 22/100\n",
      "0s - loss: 0.1432 - acc: 0.2503\n",
      "Epoch 23/100\n",
      "0s - loss: 0.1407 - acc: 0.2514\n",
      "Epoch 24/100\n",
      "0s - loss: 0.1385 - acc: 0.2521\n",
      "Epoch 25/100\n",
      "0s - loss: 0.1366 - acc: 0.2499\n",
      "Epoch 26/100\n",
      "0s - loss: 0.1342 - acc: 0.2506\n",
      "Epoch 27/100\n",
      "0s - loss: 0.1325 - acc: 0.2520\n",
      "Epoch 28/100\n",
      "0s - loss: 0.1308 - acc: 0.2519\n",
      "Epoch 29/100\n",
      "0s - loss: 0.1291 - acc: 0.2509\n",
      "Epoch 30/100\n",
      "0s - loss: 0.1277 - acc: 0.2521\n",
      "Epoch 31/100\n",
      "0s - loss: 0.1262 - acc: 0.2509\n",
      "Epoch 32/100\n",
      "0s - loss: 0.1253 - acc: 0.2492\n",
      "Epoch 33/100\n",
      "0s - loss: 0.1236 - acc: 0.2523\n",
      "Epoch 34/100\n",
      "0s - loss: 0.1219 - acc: 0.2510\n",
      "Epoch 35/100\n",
      "0s - loss: 0.1212 - acc: 0.2515\n",
      "Epoch 36/100\n",
      "0s - loss: 0.1195 - acc: 0.2530\n",
      "Epoch 37/100\n",
      "0s - loss: 0.1186 - acc: 0.2538\n",
      "Epoch 38/100\n",
      "0s - loss: 0.1174 - acc: 0.2521\n",
      "Epoch 39/100\n",
      "0s - loss: 0.1168 - acc: 0.2518\n",
      "Epoch 40/100\n",
      "0s - loss: 0.1155 - acc: 0.2523\n",
      "Epoch 41/100\n",
      "0s - loss: 0.1148 - acc: 0.2520\n",
      "Epoch 42/100\n",
      "0s - loss: 0.1137 - acc: 0.2511\n",
      "Epoch 43/100\n",
      "0s - loss: 0.1128 - acc: 0.2482\n",
      "Epoch 44/100\n",
      "0s - loss: 0.1119 - acc: 0.2539\n",
      "Epoch 45/100\n",
      "0s - loss: 0.1112 - acc: 0.2513\n",
      "Epoch 46/100\n",
      "0s - loss: 0.1104 - acc: 0.2508\n",
      "Epoch 47/100\n",
      "0s - loss: 0.1096 - acc: 0.2511\n",
      "Epoch 48/100\n",
      "0s - loss: 0.1090 - acc: 0.2514\n",
      "Epoch 49/100\n",
      "0s - loss: 0.1082 - acc: 0.2508\n",
      "Epoch 50/100\n",
      "0s - loss: 0.1076 - acc: 0.2507\n",
      "Epoch 51/100\n",
      "0s - loss: 0.1069 - acc: 0.2509\n",
      "Epoch 52/100\n",
      "0s - loss: 0.1064 - acc: 0.2525\n",
      "Epoch 53/100\n",
      "0s - loss: 0.1059 - acc: 0.2503\n",
      "Epoch 54/100\n",
      "0s - loss: 0.1053 - acc: 0.2503\n",
      "Epoch 55/100\n",
      "0s - loss: 0.1045 - acc: 0.2523\n",
      "Epoch 56/100\n",
      "0s - loss: 0.1042 - acc: 0.2509\n",
      "Epoch 57/100\n",
      "0s - loss: 0.1036 - acc: 0.2504\n",
      "Epoch 58/100\n",
      "0s - loss: 0.1030 - acc: 0.2522\n",
      "Epoch 59/100\n",
      "0s - loss: 0.1028 - acc: 0.2509\n",
      "Epoch 60/100\n",
      "0s - loss: 0.1019 - acc: 0.2542\n",
      "Epoch 61/100\n",
      "0s - loss: 0.1016 - acc: 0.2500\n",
      "Epoch 62/100\n",
      "0s - loss: 0.1013 - acc: 0.2504\n",
      "Epoch 63/100\n",
      "0s - loss: 0.1008 - acc: 0.2515\n",
      "Epoch 64/100\n",
      "0s - loss: 0.1005 - acc: 0.2518\n",
      "Epoch 65/100\n",
      "0s - loss: 0.1002 - acc: 0.2509\n",
      "Epoch 66/100\n",
      "0s - loss: 0.0999 - acc: 0.2512\n",
      "Epoch 67/100\n",
      "0s - loss: 0.0994 - acc: 0.2526\n",
      "Epoch 68/100\n",
      "0s - loss: 0.0992 - acc: 0.2501\n",
      "Epoch 69/100\n",
      "0s - loss: 0.0987 - acc: 0.2528\n",
      "Epoch 70/100\n",
      "0s - loss: 0.0987 - acc: 0.2520\n",
      "Epoch 71/100\n",
      "0s - loss: 0.0980 - acc: 0.2519\n",
      "Epoch 72/100\n",
      "0s - loss: 0.0981 - acc: 0.2498\n",
      "Epoch 73/100\n",
      "0s - loss: 0.0975 - acc: 0.2522\n",
      "Epoch 74/100\n",
      "0s - loss: 0.0975 - acc: 0.2526\n",
      "Epoch 75/100\n",
      "0s - loss: 0.0971 - acc: 0.2513\n",
      "Epoch 76/100\n",
      "0s - loss: 0.0969 - acc: 0.2517\n",
      "Epoch 77/100\n",
      "0s - loss: 0.0965 - acc: 0.2515\n",
      "Epoch 78/100\n",
      "0s - loss: 0.0964 - acc: 0.2517\n",
      "Epoch 79/100\n",
      "0s - loss: 0.0962 - acc: 0.2522\n",
      "Epoch 80/100\n",
      "0s - loss: 0.0960 - acc: 0.2497\n",
      "Epoch 81/100\n",
      "0s - loss: 0.0956 - acc: 0.2525\n",
      "Epoch 82/100\n",
      "0s - loss: 0.0955 - acc: 0.2507\n",
      "Epoch 83/100\n",
      "0s - loss: 0.0953 - acc: 0.2525\n",
      "Epoch 84/100\n",
      "0s - loss: 0.0950 - acc: 0.2534\n",
      "Epoch 85/100\n",
      "0s - loss: 0.0948 - acc: 0.2509\n",
      "Epoch 86/100\n",
      "0s - loss: 0.0948 - acc: 0.2520\n",
      "Epoch 87/100\n",
      "0s - loss: 0.0945 - acc: 0.2528\n",
      "Epoch 88/100\n",
      "0s - loss: 0.0943 - acc: 0.2510\n",
      "Epoch 89/100\n",
      "0s - loss: 0.0942 - acc: 0.2522\n",
      "Epoch 90/100\n",
      "0s - loss: 0.0940 - acc: 0.2509\n",
      "Epoch 91/100\n",
      "0s - loss: 0.0937 - acc: 0.2548\n",
      "Epoch 92/100\n",
      "0s - loss: 0.0937 - acc: 0.2522\n",
      "Epoch 93/100\n",
      "0s - loss: 0.0936 - acc: 0.2531\n",
      "Epoch 94/100\n",
      "0s - loss: 0.0934 - acc: 0.2550\n",
      "Epoch 95/100\n",
      "0s - loss: 0.0932 - acc: 0.2520\n",
      "Epoch 96/100\n",
      "0s - loss: 0.0931 - acc: 0.2511\n",
      "Epoch 97/100\n",
      "0s - loss: 0.0933 - acc: 0.2505\n",
      "Epoch 98/100\n",
      "0s - loss: 0.0930 - acc: 0.2504\n",
      "Epoch 99/100\n",
      "0s - loss: 0.0929 - acc: 0.2512\n",
      "Epoch 100/100\n",
      "0s - loss: 0.0928 - acc: 0.2508\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    nb_epoch=100,\n",
    "                       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1063,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
