{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import theano\n",
    "import numpy as np\n",
    "\n",
    "# _K = K.variable(np.array(\n",
    "#             [\n",
    "#             [[0,1,0,0],\n",
    "#              [1,0,0,0],\n",
    "#              [0,0,0,0],\n",
    "#              [0,0,0,0]],\n",
    "            \n",
    "#             [[0,0,1,0],\n",
    "#              [0,0,0,0],\n",
    "#              [1,0,0,0],\n",
    "#              [0,0,0,0]],\n",
    "                \n",
    "#             [[0,0,0,1],\n",
    "#              [0,0,0,0],\n",
    "#              [0,0,0,0],\n",
    "#              [1,0,0,0]]\n",
    "#             ]\n",
    "#              ))\n",
    "np_K = np.zeros((3,4,4))\n",
    "#_K = K.zeros((3,4,4))\n",
    "for i in range(0,3):\n",
    "    print(i)\n",
    "    np_K[i,0,i+1] = 1\n",
    "    np_K[i,i+1,0] = 1\n",
    "    \n",
    "_K = K.variable(np_K)\n",
    "\n",
    "\n",
    "def _lorentz(x, w):\n",
    "    \n",
    "    batch_size = K.shape(x)[0]\n",
    "    vector_cluster_size = K.shape(w)[0]\n",
    "    # w = K.zeros(3)\n",
    "    # x = K.zeros(4)\n",
    "    _mag = K.sqrt(K.sum(K.square(w), axis=1,keepdims=True))\n",
    "    #assert _mag.ndim == 1\n",
    "    #print(\"_w\")\n",
    "    #print(K.eval(w))\n",
    "    #print(\"_mag\")\n",
    "    #print(K.eval(_mag))\n",
    "    \n",
    "    _g = 1.#/K.sqrt(1.-K.square(_mag))\n",
    "    #assert _g.ndim == 1\n",
    "    #print(\"_g\")\n",
    "    #print(K.shape(K.eval(_g)))\n",
    "    #print(K.eval(_g))\n",
    "    \n",
    "    _inv_mag = 1/_mag\n",
    "    #print(\"_inv_mag\")\n",
    "    #print(K.eval(_inv_mag))\n",
    "    #_n = K.batch_dot(w,  _inv_mag)\n",
    "    _n = w *  _inv_mag\n",
    "    \n",
    "    #print(\"_n\")\n",
    "    #print(K.eval(K.shape(_n)))\n",
    "    #print(K.eval(_n))\n",
    "    \n",
    "    #print(\"_K\")\n",
    "    #print(K.eval(_K))\n",
    "    _bK = K.reshape(_K, (1,3,4,4))\n",
    "    \n",
    "    #print(\"_bK\")\n",
    "    #print( K.eval(_bK))\n",
    "    _bK = K.repeat_elements(_bK, vector_cluster_size, axis=0)\n",
    "    \n",
    "    #print(\"_bK\")\n",
    "    #print(K.eval(K.shape(_bK)))\n",
    "    #print( K.eval(_bK))\n",
    "    \n",
    "    _bI = K.repeat_elements(K.reshape(K.eye(4), (1,4,4)), vector_cluster_size, axis=0)\n",
    "    #print(\"_bI\")\n",
    "    #print(K.eval(K.shape(_bI)))\n",
    "    \n",
    "    _b1 = K.repeat_elements(K.eye(1),vector_cluster_size, axis=0)\n",
    "    #print(\"_b1\")\n",
    "    #print(K.eval(K.shape(_b1)))\n",
    "    #print(\"_g-_b1\")\n",
    "    #print(K.eval(K.shape(_g-_b1)))\n",
    "    \n",
    "    #assert _n.ndim == 2\n",
    "    _nK = K.batch_dot(_n, _bK, axes=[[1],[1]])\n",
    "    #_nK = _n * _K\n",
    "    _nK = K.reshape(_nK, (vector_cluster_size,1,4,4))\n",
    "    #print(\"_nK\")\n",
    "    #print(K.eval(K.shape(_nK)))\n",
    "    #print(K.eval(_nK))\n",
    "    \n",
    "    #print(\"_g*_mag\")\n",
    "    #print(K.eval(K.shape(K.sum(_g*_mag, axis=1))))\n",
    "    #r = K.batch_dot(_g*_mag, _nK, axes=[[1],[1]])\n",
    "    #print(K.eval(r))\n",
    "    #print(K.shape(K.eval(r)))\n",
    "    #print(K.eval(K.batch_dot(K.sum(_g*_mag, axis=1), _nK)))\n",
    "    \n",
    "    #print(\"_nk2\")\n",
    "    #print(K.eval(K.batch_dot(_nK,_nK)))\n",
    "    #K.repeat(K.eye(4), K.shape(w)[0])  -\n",
    "    #*K.batch_dot(_nK,_nK)\n",
    "    _nKr = K.reshape(_nK, (vector_cluster_size,1,4,4))\n",
    "    _nK2r = K.reshape(K.batch_dot(_nK,_nK), (vector_cluster_size,1,4,4))\n",
    "    _B = _bI - K.batch_dot(_g*_mag, _nKr, axes=[[1],[1]]) +K.batch_dot(_g-_b1,_nK2r,axes=[[1],[1]])\n",
    "    \n",
    "    #print(\"_B\")\n",
    "    #print(K.shape(K.eval(_B)))\n",
    "    #print(K.eval(_B))\n",
    "    \n",
    "    x_shape = K.shape(x)\n",
    "    x = K.reshape(x, (x_shape[0],x_shape[1], 1, 4))\n",
    "    _B = K.reshape(_B, (1,vector_cluster_size,4,4))\n",
    "    _mB = K.repeat_elements(_B,batch_size, axis=0)\n",
    "    \n",
    "    #print(\"_mB\")\n",
    "    #print(K.shape(K.eval(_mB)))\n",
    "    #print(K.eval(_mB))\n",
    "    #r = K.variable(np.random.random((50, 12,4)))\n",
    "    #r = K.reshape(r, (50, 12,1,4))\n",
    "    #print(\"r\")\n",
    "    #print(K.shape(K.eval(r)))\n",
    "    #print(K.eval(r))\n",
    "    \n",
    "    #out = x + _mB\n",
    "    #out = K.dot(_mB, x, axes=[[1],[1]])\n",
    "    out = K.reshape(K.batch_dot(_mB, x, axes=[[1,3],[1,3]]), (batch_size, 1,4))\n",
    "    \n",
    "    #print(\"out\")\n",
    "    #print(K.shape(K.eval(out)))\n",
    "    #print(K.eval(out))\n",
    "    #f = lambda x_i: K.batch_dot(x_i, _B, axes=[[1],[1]])\n",
    "    #for\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LorentzLayer(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(LorentzLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        print(input_shape)\n",
    "        ## the input shape should be (..., 4)\n",
    "        # weights are including\n",
    "        input_dim = input_shape[1]\n",
    "        ## angle1, angle2, beta : dim 3\n",
    "        initial_weight_value = np.random.random((input_dim,3))\n",
    "        print(initial_weight_value.shape)\n",
    "        initial_bias_value = np.random.random((1,3))\n",
    "        print(initial_bias_value.shape)\n",
    "        self.W = K.variable(initial_weight_value)\n",
    "        self.B = K.variable(initial_bias_value)\n",
    "        # self.trainable_weights = [self.W]\n",
    "        self.trainable_weights = [self.W, self.B]\n",
    "\n",
    "    def call(self, T, mask=None):\n",
    "        print(\"call\")\n",
    "        print(type(T[0]))\n",
    "        print(T[0])\n",
    "        # should get a tensor (N,4) corresponding to n 4-vesctors\n",
    "        #lorentzboost of the vectorial sum of each lorentzboosted 4 vector\n",
    "        return _lorentz(_lorentz( T, self.W ), self.B)\n",
    "        #return K.sum(T, axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        print(\"get ouput shape\")\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 12, 4)\n",
      "(12, 3)\n",
      "(3,)\n",
      "call\n",
      "<class 'theano.tensor.var.TensorVariable'>\n",
      "Subtensor{int64}.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough dimensions on Elemwise{sqr,no_inplace}.0 to reduce on axis 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-652-eb3bc762f29f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLorentzLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m model.compile(loss='mean_squared_error',\n\u001b[0;32m      8\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                     \u001b[0minput_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_input_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_input_layer\u001b[1;34m(self, batch_input_shape, input_dtype, name)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[1;31m# this will call layer.build() if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m             \u001b[0minput_added\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36madd_inbound_node\u001b[1;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0mNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_node\u001b[1;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m             \u001b[0moutput_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;31m# TODO: try to auto-infer shape if exception is raised by get_output_shape_for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-651-f348439b612c>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, T, mask)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# should get a tensor (N,4) corresponding to n 4-vesctors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;31m#lorentzboost of the vectorial sum of each lorentzboosted 4 vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_lorentz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_lorentz\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;31m#return K.sum(T, axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-651-f348439b612c>\u001b[0m in \u001b[0;36m_lorentz\u001b[1;34m(x, w)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# w = K.zeros(3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# x = K.zeros(4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0m_mag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;31m#assert _mag.ndim == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m#print(\"_w\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(x, axis, keepdims)\u001b[0m\n\u001b[0;32m    181\u001b[0m     '''Sum of the values in a tensor, alongside the specified axis.\n\u001b[0;32m    182\u001b[0m     '''\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.2-py2.7.egg/theano/tensor/basic.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(input, axis, dtype, keepdims, acc_dtype)\u001b[0m\n\u001b[0;32m   2927\u001b[0m     \"\"\"\n\u001b[0;32m   2928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2929\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melemwise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macc_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2931\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.2-py2.7.egg/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \"\"\"\n\u001b[0;32m    610\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'return_list'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'off'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.2-py2.7.egg/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macc_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1909\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mCAReduce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/Theano-0.8.2-py2.7.egg/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                     raise ValueError((\n\u001b[0;32m   1373\u001b[0m                         \u001b[1;34m'Not enough dimensions on %s to reduce on axis %s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                         % (input, axis)))\n\u001b[0m\u001b[0;32m   1375\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_tensor_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Not enough dimensions on Elemwise{sqr,no_inplace}.0 to reduce on axis 1"
     ]
    }
   ],
   "source": [
    "# %load compile.py\n",
    "#Compile\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "model = Sequential()\n",
    "model.add(LorentzLayer(4 ,input_shape=(12,4)))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = [[(8, 1, 1, 1),\n",
    "#          (7, 2, 1, 2),\n",
    "#          (10, 1, 2, 1),\n",
    "#          (16, 1, 1, 2),\n",
    "#          (20, 3, 1, 1)]]\n",
    "#y_train = [(15, 1, 1, 2)]\n",
    "\n",
    "x_train = np.random.random((1000, 12, 4))\n",
    "y_train = np.random.random((1000, 4))\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=50,\n",
    "                    nb_epoch=100,\n",
    "                       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
