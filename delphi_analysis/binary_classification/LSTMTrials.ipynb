{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is disabled, cuDNN not available)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "using gpu1\n",
      "using theano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#We can go into our root file and see what Trees are availiable\n",
    "%matplotlib inline\n",
    "import sys, os\n",
    "if __package__ is None:\n",
    "    import sys, os\n",
    "    sys.path.append(os.path.realpath(\"/data/shared/Software/\"))\n",
    "    sys.path.append(os.path.realpath(\"../../\"))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import glob\n",
    "import deepconfig\n",
    "\n",
    "from keras.utils.visualize_util import plot\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from CMS_SURF_2016.utils.preprocessing import ObjectProfile, \\\n",
    "        preprocessFromPandas_label_dir_pairs, label_dir_pairs_args_decoder, \\\n",
    "        genFrom_label_dir_pairs,maxMutualLength, start_num_fromSplits\n",
    "from CMS_SURF_2016.utils.metrics import plot_history, print_accuracy_m\n",
    "from CMS_SURF_2016.utils.callbacks import OverfitStopping, SmartCheckpoint\n",
    "from CMS_SURF_2016.utils.archiving import *\n",
    "from CMS_SURF_2016.layers.lorentz import Lorentz, _lorentz\n",
    "from CMS_SURF_2016.layers.slice import Slice\n",
    "\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Flatten, Reshape, Activation, Dropout, Convolution2D, merge, Input, Flatten, Lambda, LSTM, Masking\n",
    "from keras.engine.topology import Layer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "\n",
    "dc = deepconfig.deepconfig(gpu='gpu0', backend='theano')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The observables taken from the table\n",
    "observ_types = ['E/c', 'Px', 'Py', 'Pz', 'Charge', \"PT_ET\", \"Eta\", \"Phi\", \"Dxy_Ehad_Eem\"]\n",
    "vecsize = len(observ_types)\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "sample_start = 0\n",
    "num_samples = 10000\n",
    "\n",
    "\n",
    "object_profiles = [ObjectProfile(\"Electron\",5),\n",
    "                    ObjectProfile(\"MuonTight\", 5),\n",
    "                    ObjectProfile(\"Photon\", 25),\n",
    "                    ObjectProfile(\"MissingET\", 1),\n",
    "                    ObjectProfile(\"EFlowPhoton\",100, sort_columns=[\"PT_ET\"], sort_ascending=False),  #1300\n",
    "                    ObjectProfile(\"EFlowNeutralHadron\",100, sort_columns=[\"PT_ET\"], sort_ascending=False),  #1000\n",
    "                    ObjectProfile(\"EFlowTrack\",100, sort_columns=[\"PT_ET\"], sort_ascending=False)]  #1050\n",
    "\n",
    "\n",
    "label_dir_pairs = \\\n",
    "            [   (\"ttbar\", \"/data/shared/Delphes/ttbar_lepFilter_13TeV/pandas_unjoined/\"),\n",
    "                (\"wjet\", \"/data/shared/Delphes/wjets_lepFilter_13TeV/pandas_unjoined/\"),\n",
    "                (\"qcd\", \"/data/shared/Delphes/qcd_lepFilter_13TeV/pandas_unjoined/\")\n",
    "            ]\n",
    "#ttbar_files = glob.glob(\"/data/shared/Delphes/ttbar_lepFilter_13TeV/pandas_unjoined/*.h5\")\n",
    "#WJet_files = glob.glob(\"/data/shared/Delphes/wjets_lepFilter_13TeV/pandas_unjoined/*.h5\")\n",
    "#qcd_files = glob.glob(\"/data/shared/Delphes/qcd_lepFilter_13TeV/pandas_unjoined/*.h5\")\n",
    "\n",
    "#files = {0:ttbar_files, 1:WJet_files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genModel(name,out_dim, depth, lstm_activation=\"relu\", lstm_dropout = 0.0, dropout=0.0):\n",
    "    inputs = []\n",
    "    mergelist = []\n",
    "    for i, profile in enumerate(object_profiles):\n",
    "        # print(o)\n",
    "        inp = a = Input(shape=(profile.max_size, vecsize), name=\"input_\"+str(i))\n",
    "        inputs.append(inp)\n",
    "        #a = Flatten(name=\"flatten_\"+str(i))(a)\n",
    "        # b2 = Dense(10, activation='relu')(b2)\n",
    "        mergelist.append(a)\n",
    "    # print(mergelist)\n",
    "    a = merge(mergelist,mode='concat',concat_axis=1, name=\"merge\")\n",
    "    # a = Flatten()(a)\n",
    "    for i in range(depth):\n",
    "        a = Masking(mask_value=0.0)(a)\n",
    "        a = LSTM(vecsize,\n",
    "                 input_shape=(None,vecsize),\n",
    "                 dropout_W=lstm_dropout,\n",
    "                 dropout_U=lstm_dropout,\n",
    "                 activation=lstm_activation,\n",
    "                 name = \"lstm_\" +str(i))(a)\n",
    "        if(dropout > 0.0):\n",
    "            a =  Dropout(dropout, name=\"dropout_\"+str(i))(a)\n",
    "    dense_out = Dense(out_dim, activation='sigmoid', name='main_output')(a)\n",
    "    model = Model(input=inputs, output=dense_out, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-c848c0f87c3a>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-c848c0f87c3a>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    labels = [x[0] for x in ldps]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "archive_dir = \"/data/shared/Delphes/keras_archive/\"\n",
    "earlyStopping = EarlyStopping(verbose=1, patience=10)\n",
    "overfitStopping = OverfitStopping(verbose=1, patience=20)\n",
    "trials = []\n",
    "ldps_pairs = []\n",
    "for i, j in [(2,0)]:\n",
    "    ldps = [label_dir_pairs[i]] + [label_dir_pairs[j]]\n",
    "    SNs = start_num_fromSplits((.7,.15,.15), maxMutualLength(label_dir_pairs, object_profiles))\n",
    "    print(SNs)\n",
    "    gen_lambda =  lambda s : (DataProcedure(archive_dir,\n",
    "                                           False,\n",
    "                                           genFrom_label_dir_pairs,\n",
    "                                           start=s[0],\n",
    "                                           samples_per_label=s[1],\n",
    "                                           stride=10000,\n",
    "                                            batch_size=100,\n",
    "                                           archive_dir=archive_dir,\n",
    "                                           label_dir_pairs=ldps,\n",
    "                                           object_profiles=object_profiles,\n",
    "                                           observ_types=observ_types),\n",
    "                             len(ldps)*s[1])\n",
    "    l = [gen_lambda(s) for s in SNs]\n",
    "    train, num_train = l[0]\n",
    "    val,   num_val   = l[1]\n",
    "    test,  num_test  = l[2]\n",
    "    \n",
    "    \n",
    "   \n",
    "    #gg = train.getData()\n",
    "    \n",
    "#    count = 10\n",
    "#    for X,Y in gg:\n",
    "#        for Xi in X:\n",
    "#            print(Xi.shape)\n",
    "#        print('')\n",
    "#        for Yi in Y:\n",
    "#            print(Yi.shape)\n",
    "#        print('')\n",
    "#        count -= 1\n",
    "#        if(count == 0): raise ValueError()\n",
    "        \n",
    "    \n",
    "    labels = [x[0] for x in ldps]\n",
    "    for name in ['LSTM']:\n",
    "        for depth in [1]:\n",
    "            #for width in [100]:\n",
    "                for activation in ['tanh']:\n",
    "                    for lstm_dropout in [0.0]:\n",
    "                        for dropout in [0.0]:\n",
    "                            activation_name = activation if isinstance(activation, str) \\\n",
    "                                                else activation.__name__\n",
    "\n",
    "                            model = genModel(name, len(ldps), depth, activation, lstm_dropout, dropout)\n",
    "\n",
    "                            print(model.summary())\n",
    "\n",
    "                            trial = KerasTrial(archive_dir, name=name, model=model)\n",
    "\n",
    "                            trial.setTrain(train_procedure=train,\n",
    "                                           samples_per_epoch=num_train\n",
    "                                          )\n",
    "                            trial.setValidation(val_procedure=val,\n",
    "                                               nb_val_samples=num_val)\n",
    "                            trial.setCompilation(loss='binary_crossentropy',\n",
    "                                      optimizer='rmsprop',\n",
    "                                      metrics=['accuracy']\n",
    "                                          )\n",
    "                            trial.setFit_Generator( \n",
    "                                            nb_epoch=epochs,\n",
    "                                            callbacks=[earlyStopping, overfitStopping])\n",
    "\n",
    "\n",
    "\n",
    "                            print(\"EXECUTE: \", name,labels, depth, activation_name)\n",
    "                            trial.execute(custom_objects={\"Lorentz\":Lorentz,\"Slice\": Slice},\n",
    "                                         train_arg_decode_func=label_dir_pairs_args_decoder,\n",
    "                                         val_arg_decode_func=label_dir_pairs_args_decoder)\n",
    "\n",
    "\n",
    "                            trial.test(test_proc=test,\n",
    "                                         test_samples=num_test,\n",
    "                                         custom_objects={\"Lorentz\":Lorentz,\"Slice\": Slice},\n",
    "                                        arg_decode_func = label_dir_pairs_args_decoder)\n",
    "\n",
    "\n",
    "\n",
    "                            trial.to_record({\"lables\": labels,\n",
    "                                             \"depth\": depth,\n",
    "                                             #\"width\": width,\n",
    "                                             \"activation\": activation_name,\n",
    "                                             \"dropout\":dropout,\n",
    "                                             \"lstm_dropout\":lstm_dropout\n",
    "                                            })\n",
    "                                       \n",
    "\n",
    "                \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
