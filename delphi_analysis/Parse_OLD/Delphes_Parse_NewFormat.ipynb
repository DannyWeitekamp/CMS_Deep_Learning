{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/04\n"
     ]
    }
   ],
   "source": [
    "#WARNING THIS SCRIPT TAKES A LONG TIME TO RUN!\n",
    "#Note Everythin is in natural units so C = 1\n",
    "import sys, os\n",
    "if __package__ is None:\n",
    "    import sys, os\n",
    "    sys.path.append(os.path.realpath(\"/data/shared/Software/\"))\n",
    "    sys.path.append(os.path.realpath(\"../../\"))\n",
    "from CMS_SURF_2016.utils.data_parse import ROOT_to_pandas\n",
    "from CMS_SURF_2016.utils.data_parse import DataProcessingProcedure\n",
    "from CMS_SURF_2016.utils.data_parse import leaves_from_obj\n",
    "import ROOT\n",
    "from ROOT import TTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import glob\n",
    "from itertools import cycle, islice\n",
    "\n",
    "#didit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cullNonObservables(frame):\n",
    "    #Status of 1 means that the particle is a stable product\n",
    "    stable_cond = frame[\"Status\"] == 1 \n",
    "    #All even leptons are neutrinos which we can't measure\n",
    "    notNeutrino_cond = frame[\"PID\"] % 2 == 1\n",
    "    parton_cond = np.abs(frame[\"PID\"]) <= 8\n",
    "    #Get all entries that satisfy the conditions\n",
    "    frame = frame[stable_cond & notNeutrino_cond]\n",
    "    #Drop the Status frame since we only needed it to see if the particle was stable\n",
    "    frame = frame.drop([\"Status\"], axis=1)\n",
    "    return frame\n",
    "\n",
    "#Define the speed of light C\n",
    "#Turns C=1 since everything is in natural units :/\n",
    "#C = np.float64(2.99792458e8); #m/s\n",
    "mass_of_electron = np.float64(0.0005109989461) #eV/c\n",
    "mass_of_muon = np.float64(0.1056583715)      #eV/c\n",
    "#def four_vec_func(inputs):\n",
    "#        E = inputs[0]\n",
    "#        Eta = inputs[1]\n",
    "#        Phi = inputs[2]\n",
    "#        PT = inputs[3]\n",
    "#        E_over_c = E/C\n",
    "#        px = E_over_c * np.sin(Phi) * np.cos(Eta) \n",
    "#        py = E_over_c * np.sin(Phi) * np.sin(Eta)\n",
    "#        pz = E_over_c * np.cos(Phi)\n",
    "#        print(np.sqrt(px*px + py*py), PT/C)\n",
    "#        return [E_over_c, px, py, pz]\n",
    "\n",
    "#def getPandasPhotons(filename):\n",
    "#    four_vec_inputs, dummy = leaves_from_obj(\"Photon\", [\"PT\", \"Eta\", \"Phi\"])\n",
    "#    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0), four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "\n",
    "#    PID_proc = DataProcessingProcedure(lambda x:[22], [], [\"PID\"])\n",
    "#    charge_proc = DataProcessingProcedure(lambda x:[0], [], [\"Charge\"])\n",
    "\n",
    "#    columns=[four_vec_proc, PID_proc, charge_proc]\n",
    "#    leaves, columns = leaves_from_obj(\"Photon\", columns+[\"PT\", \"Eta\", \"Phi\"])\n",
    "\n",
    "#    photon_frame = ROOT_to_pandas(filename,\n",
    "#                          leaves,\n",
    "#                          columns=columns,\n",
    "#                          verbosity=1)\n",
    "#    return photon_frame\n",
    "\n",
    "\n",
    "extra_data = [\"PT\", \"Phi\", \"Eta\"]\n",
    "dxy_proc = [DataProcessingProcedure(lambda x: [0], [], [\"Dxy\"])]\n",
    "elfow_proc = [DataProcessingProcedure(lambda x: [0,0], [], [\"Eem\", \"Ehad\"])]\n",
    "\n",
    "\n",
    "def four_vec_from_PT(inputs, M):\n",
    "    #print(type(inputs[0]))\n",
    "    PT = inputs[0] #Units ?\n",
    "    Eta = inputs[1]\n",
    "    Phi = inputs[2]\n",
    "    #M has units of eV/(c^2)\n",
    "    if(M == None):\n",
    "        M = inputs[3]\n",
    "    momentum_mag = PT * np.cosh(Eta)\n",
    "    #if(~didit):\n",
    "    #print(momentum_mag, PT, np.cosh(Eta))\n",
    "    #    didit = True\n",
    "    E_over_c = np.sqrt(np.square(M) + np.square(momentum_mag))\n",
    "    #print(PT/np.sin(Phi))\n",
    "    px = PT * np.cos(Phi) \n",
    "    py = PT * np.sin(Phi) \n",
    "    pz = PT * np.sinh(Eta)\n",
    "    return [E_over_c, px, py, pz]\n",
    "\n",
    "def getPandasParticles(filename, cull=True):\n",
    "    #C=1 in natural units so no processing needs to be done\n",
    "    E_over_c_proc = DataProcessingProcedure(lambda x:x[0], [\"Particle.E\"], [\"E/c\"])\n",
    "    columns= [E_over_c_proc, \"Px\", \"Py\", \"Pz\", \"PID\", \"Charge\"]#, \"Status\"]\n",
    "    leaves, columns = leaves_from_obj(\"Particle\", columns+extra_data + dxy_proc + elfow_proc)\n",
    "    original_frame = ROOT_to_pandas(filename,\n",
    "                                 leaves,\n",
    "                                  columns=columns,\n",
    "                                  verbosity=1)\n",
    "    if(cull):\n",
    "        particle_frame = cullNonObservables(original_frame)\n",
    "    else:\n",
    "        particle_frame = original_frame\n",
    "    return particle_frame\n",
    "\n",
    "\n",
    "def getPandasSpecificParticles(filename, name, mass=None, pid=None, chrg_def=-1, charge=None):\n",
    "    if(mass != None):\n",
    "        four_vec_inputs, dummy = leaves_from_obj(name, [\"PT\", \"Eta\", \"Phi\"])\n",
    "    else:\n",
    "        four_vec_inputs, dummy = leaves_from_obj(name, [\"PT\", \"Eta\", \"Phi\", \"Mass\"])\n",
    "        \n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,mass)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    \n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    \n",
    "    if(charge == None):\n",
    "        if(pid != None):\n",
    "            PID_charge_proc = DataProcessingProcedure(lambda x: [pid*chrg_def*x[0], x[0]]\n",
    "                                                      , [name + \".Charge\"], [\"PID\", \"Charge\"])\n",
    "            columns=[four_vec_proc, PID_charge_proc]#, status_proc]\n",
    "        else:\n",
    "            columns=[four_vec_proc, \"PID\", \"Charge\"]#, status_proc]\n",
    "    else:\n",
    "        charge_proc = DataProcessingProcedure(lambda x: [charge], [], [\"Charge\"])\n",
    "        if(pid != None):\n",
    "            PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "            columns=[four_vec_proc, PID_proc, charge_proc]#,status_proc]\n",
    "        else:\n",
    "            columns=[four_vec_proc, \"PID\", charge_proc]#,status_proc]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    leaves, columns = leaves_from_obj(name, columns+extra_data + dxy_proc + elfow_proc)\n",
    "\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "\n",
    "def getPandasPhotons(filename):\n",
    "    return getPandasSpecificParticles(filename, \"Photon\", mass=0, pid=22, charge=0)\n",
    "\n",
    "def getPandasElectrons(filename):\n",
    "    return getPandasSpecificParticles(filename, \"Electron\", mass=mass_of_electron, pid=11)\n",
    "\n",
    "def getPandasTightMuons(filename):\n",
    "    return getPandasSpecificParticles(filename, \"MuonTight\", mass=mass_of_muon, pid=13)\n",
    "\n",
    "def getPandasJets(filename):\n",
    "    return getPandasSpecificParticles(filename, \"Jet\", pid=100, chrg_def=1)\n",
    "\n",
    "def getPandasMissingET(filename, name=\"MissingET\"):  \n",
    "    pid = 83\n",
    "    if(name == \"PuppiMissingET\"): pid=84\n",
    "    four_vec_inputs, dummy = leaves_from_obj(name, [\"MET\", \"Eta\", \"Phi\"])\n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    charge_proc = DataProcessingProcedure(lambda x: [0], [], [\"Charge\"])\n",
    "    PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "    columns=[four_vec_proc, PID_proc, charge_proc]#, status_proc]\n",
    "    met_proc = DataProcessingProcedure(lambda x: [x[0]], [\"MissingET.MET\"], [\"PT\"] )\n",
    "    \n",
    "    ex = [x if (x != \"PT\") else met_proc for x in extra_data]\n",
    "    leaves, columns = leaves_from_obj(name, columns+ex + dxy_proc + elfow_proc)\n",
    "\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "def getPandasEFlowParticle(filename, name=\"EFlowPhoton\"):  \n",
    "    pid = 90\n",
    "    if(name == \"EFlowNeutralHadron\"): pid=91\n",
    "    four_vec_inputs, dummy = leaves_from_obj(name, [\"ET\", \"Eta\", \"Phi\"])\n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    charge_proc = DataProcessingProcedure(lambda x: [0], [], [\"Charge\"])\n",
    "    PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "    columns=[four_vec_proc, PID_proc, charge_proc]#, status_proc]\n",
    "    \n",
    "    \n",
    "    et_proc = DataProcessingProcedure(lambda x: [x[0]], [name+\".ET\"], [\"PT\"] )\n",
    "    \n",
    "    ex = [x if (x != \"PT\") else et_proc for x in extra_data]\n",
    "    leaves, columns = leaves_from_obj(name, columns+ex + dxy_proc + [\"Eem\", \"Ehad\"])\n",
    "\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "\n",
    "def getPandasEFlowTrack(filename):  \n",
    "    pid = 89\n",
    "    four_vec_inputs, dummy = leaves_from_obj(\"EFlowTrack\", [\"PT\", \"Eta\", \"Phi\"])\n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    #charge_proc = DataProcessingProcedure(lambda x: [0], [], [\"Charge\"])\n",
    "    PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "    columns=[four_vec_proc, PID_proc, \"Charge\"]#, status_proc]\n",
    "    \n",
    "    \n",
    "    #et_proc = DataProcessingProcedure(lambda x: [x[0]], [name+\".ET\"], [\"PT\"] )\n",
    "    \n",
    "    #ex = [x if (x != \"PT\") else et_proc for x in extra_data]\n",
    "    leaves, columns = leaves_from_obj(\"EFlowTrack\", columns+extra_data + [\"Dxy\"] + elfow_proc)\n",
    "    print(leaves, columns)\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "\n",
    "\n",
    "#def getPandasAll(filename, cull=False, includePuppi=True):\n",
    "#    lst = [getPandasPhotons(filename),\n",
    "#                    getPandasElectrons(filename),\n",
    "#                    getPandasTightMuons(filename),\n",
    "#                    getPandasJets(filename),\n",
    "#                    getPandasParticles(filename, cull=cull),\n",
    "#                    getPandasMissingET(filename)]\n",
    "#    \n",
    "#    if(includePuppi):\n",
    "#        lst = lst + [getPandasMissingET(filename, \"PuppiMissingET\")]\n",
    "#    #Merge all these frames\n",
    "#    out = pd.concat(lst)\n",
    "#    return out\n",
    "\n",
    "def getPandasAll(filename, cull=False, includePuppi=False):\n",
    "    lst = [getPandasPhotons(filename),\n",
    "                    getPandasElectrons(filename),\n",
    "                    getPandasTightMuons(filename),\n",
    "                    getPandasEFlowParticle(filename, name=\"EFlowNeutralHadron\"),\n",
    "                    getPandasEFlowParticle(filename, name=\"EFlowPhoton\"),\n",
    "                    getPandasEFlowTrack(filename),\n",
    "                    getPandasMissingET(filename)]\n",
    "    \n",
    "    if(includePuppi):\n",
    "        lst = lst + [getPandasMissingET(filename, \"PuppiMissingET\")]\n",
    "    #Merge all these frames\n",
    "    out = pd.concat(lst)\n",
    "    return out\n",
    "\n",
    "#def getPandasAll(filename):\n",
    "#    out = pd.concat([getPandasPhotons(filename),getPandasParticles(filename, cull=False)])\n",
    "#    return out\n",
    "\n",
    "#http://stackoverflow.com/questions/3678869/pythonic-way-to-combine-two-lists-in-an-alternating-fashion\n",
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    pending = len(iterables)\n",
    "    nexts = cycle(iter(it).next for it in iterables)\n",
    "    while pending:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            pending -= 1\n",
    "            nexts = cycle(islice(nexts, pending))\n",
    "\n",
    "    \n",
    "def storeAllUnjoined(filepath, outputDir, rerun=False):\n",
    "    \n",
    "    filename = os.path.splitext(ntpath.basename(filepath))[0]\n",
    "    \n",
    "    name_cols = [(\"EFlowTrack\", [\"PT\", \"Eta\", \"Phi\", \"Dxy\", \"Charge\"]),\n",
    "                 (\"EFlowPhoton\", [\"ET\", \"Eta\", \"Phi\", \"Eem\", \"Ehad\"]),\n",
    "                 (\"EFlowNeutralHadron\", [\"ET\", \"Eta\", \"Phi\", \"Eem\", \"Ehad\"]),\n",
    "                 (\"Electron\", [\"PT\", \"Eta\", \"Phi\", \"Charge\"]),\n",
    "                 (\"MuonTight\", [\"PT\", \"Eta\", \"Phi\", \"Charge\"]),\n",
    "                 (\"MissingET\", [\"MET\", \"Eta\", \"Phi\"])]\n",
    "    for nc in name_cols:\n",
    "        name = nc[0]\n",
    "        cols = nc[1]\n",
    "        out_file = outputDir + name + \"/\" + filename + \".h5\"\n",
    "        leaves, columns = leaves_from_obj(name,cols)\n",
    "        if not os.path.exists(outputDir+name):\n",
    "            os.makedirs(outputDir+name)\n",
    "        if(rerun or os.path.isfile(out_file) == False):\n",
    "            #print(rerun, ~os.path.isfile(out_file), out_file)\n",
    "            frame = ROOT_to_pandas(filepath, leaves, columns=columns)\n",
    "            frame.to_hdf(out_file, 'data', mode='w')\n",
    "\n",
    "def storeAllJoined(filepath, outputfile, rerun=False):\n",
    "    if(rerun or os.path.isfile(outputfile) == False):\n",
    "        #print(rerun, ~os.path.isfile(out_file), out_file)\n",
    "        frame = getPandasAll(filepath)\n",
    "        frame.to_hdf(outputfile, 'data', mode='w')\n",
    "    \n",
    "\n",
    "    \n",
    "def makeJobs(filename, job_types,\n",
    "             directory=\"/data/shared/Delphes/\",\n",
    "             unjoined_folder=\"/pandas_unjoined/\",\n",
    "             joined_folder=\"/pandas_joined/\"):\n",
    "    files = glob.glob(directory + filename + \"/*.root\")\n",
    "    unjoined_dir = directory + filename + unjoined_folder\n",
    "    joined_dir = directory + filename + joined_folder\n",
    "    if not os.path.exists(joined_dir):\n",
    "        os.makedirs(joined_dir)\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    for f in files:\n",
    "        f_name = os.path.splitext(ntpath.basename(f))[0]\n",
    "        for j_type in job_types:\n",
    "            if(j_type == \"unjoined\"):\n",
    "                jobs.append((j_type,f, unjoined_dir))\n",
    "            elif(j_type == \"joined\"):\n",
    "                jobs.append((j_type,f, joined_dir + f_name + \".h5\"))\n",
    "\n",
    "    return jobs\n",
    "    \n",
    "    \n",
    "#def groupEntriesToArrays(frame, select):\n",
    "#    out = []\n",
    "#    m = frame['Entry'].max()\n",
    "#    for entry in range(0, m+1):\n",
    "#        cond = frame['Entry'] == entry\n",
    "#        entry_frame = frame[cond]\n",
    "#        entry_frame = entry_frame[select]\n",
    "#        arr = np.array(entry_frame)\n",
    "#        np.random.shuffle(arr)\n",
    "#        out.append(arr)\n",
    "#    return out\n",
    "\n",
    "#def groupEntriesToArrays(frame, select):\n",
    "#    grouped = frame.groupby([\"Entry\"]).apply(lambda df: df[select].tolist())\n",
    "    #print(grouped)\n",
    "#    return grouped\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttbar_files = glob.glob(\"/data/shared/Delphes/ttbar_lepFilter_13TeV/*.root\")\n",
    "# WJet_files = glob.glob(\"/data/shared/Delphes/wjets_lepFilter_13TeV/*.root\")\n",
    "# WJet_files = glob.glob(\"/data/shared/Delphes/qcd_lepFilter_13TeV/*.root\")\n",
    "\n",
    "#frame = getPandasEFlowParticle(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasEFlowParticle(ttbar_files[0], \"EFlowNeutralHadron\")\n",
    "#print(frame)\n",
    "#frame = getPandasEFlowTrack(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasPhotons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasElectrons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasTightMuons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasMissingET(ttbar_files[0])\n",
    "#print(frame)\n",
    "\n",
    "ttbar_jobs = makeJobs(\"ttbar_lepFilter_13TeV\", [\"joined\"])\n",
    "WJet_jobs = makeJobs(\"wjets_lepFilter_13TeV\", [\"joined\"])\n",
    "qcd_jobs = makeJobs(\"qcd_lepFilter_13TeV\", [\"joined\"])\n",
    "#ttbar_jobs = makeJobs(\"ttbar_lepFilter_13TeV\", [\"unjoined\"])\n",
    "#WJet_jobs = makeJobs(\"wjets_lepFilter_13TeV\", [\"unjoined\"])\n",
    "#qcd_jobs = makeJobs(\"qcd_lepFilter_13TeV\", [\"unjoined\"])\n",
    "    \n",
    "jobs = roundrobin(ttbar_jobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool\n",
    "# from multiprocessing import Process, Queue\n",
    "# import time\n",
    "\n",
    "def doJob(job):\n",
    "    if(job[0] == \"unjoined\"):\n",
    "        print(\"Started: \", job[1])\n",
    "        #storeAllUnjoined(job[1], job[2])\n",
    "    elif(job[0] == \"joined\"):\n",
    "        #print(job)\n",
    "        storeAllJoined(job[1], job[2])\n",
    "    return job[1]\n",
    "\n",
    "# pool = Pool(4)\n",
    "\n",
    "# def mycallback(x):\n",
    "#     print(\"Finished: \", x)\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "# results = []\n",
    "# for job in jobs:\n",
    "#     r = pool.apply_async(doJob, args=[job], callback=mycallback)\n",
    "#     results.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from /data/shared/Delphes/ttbar_lepFilter_13TeV/ttbar_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['Photon.PT', 'Photon.Eta', 'Photon.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"[] -> ['PID']\"\n",
      "Procedure at column 6 maps \"[] -> ['Charge']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Procedure at column 11 maps \"[] -> ['Eem', 'Ehad']\"\n",
      "Extracting Leaves: Photon.PT, Photon.Eta, Photon.Phi, Photon.PT, Photon.Phi, Photon.Eta\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[=================== ] 9759/10000       Entry         E/c         Px         Py          Pz  ...        Phi  \\\n",
      "0          0  100.326318   3.786404  32.418321  -94.868781  ...   1.454525   \n",
      "1          0   31.724228   6.469687 -24.526153   19.053547  ...  -1.312884   \n",
      "2          1   12.361107  -9.094426   4.213835   -7.234084  ...   2.707699   \n",
      "3          3  186.971185   3.616766 -12.073635 -186.545893  ...  -1.279744   \n",
      "4          4   93.192251  -3.596121  18.837289   91.197698  ...   1.759431   \n",
      "...      ...         ...        ...        ...         ...  ...        ...   \n",
      "15674   9994  247.078131   6.576936   8.972419  246.827556  ...   0.938253   \n",
      "15675   9995   14.578775   6.674037   9.810588    8.470553  ...   0.973422   \n",
      "15676   9997   24.536420   9.074290   5.124458   22.213354  ...   0.514076   \n",
      "15677   9998   45.284771 -42.230703  -7.767404  -14.385605  ...  -2.959698   \n",
      "15678   9999   35.844787  21.921834  14.094262   24.609627  ...   0.571391   \n",
      "\n",
      "            Eta  Dxy  Eem  Ehad  \n",
      "0     -1.788501    0    0     0  \n",
      "1      0.694084    0    0     0  \n",
      "2     -0.670379    0    0     0  \n",
      "3     -3.388972    0    0     0  \n",
      "4      2.263316    0    0     0  \n",
      "...         ...  ...  ...   ...  \n",
      "15674  3.793171    0    0     0  \n",
      "15675  0.664000    0    0     0  \n",
      "15676  1.500961    0    0     0  \n",
      "15677 -0.329053    0    0     0  \n",
      "15678  0.841421    0    0     0  \n",
      "\n",
      "[15679 rows x 13 columns]\n",
      "Elapse time: 8.18 seconds\n",
      "Extracting data from /data/shared/Delphes/ttbar_lepFilter_13TeV/ttbar_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['Electron.PT', 'Electron.Eta', 'Electron.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"['Electron.Charge'] -> ['PID', 'Charge']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Procedure at column 11 maps \"[] -> ['Eem', 'Ehad']\"\n",
      "Extracting Leaves: Electron.PT, Electron.Eta, Electron.Phi, Electron.Charge, Electron.PT, Electron.Phi, Electron.Eta\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[=================== ] 9759/10000      Entry         E/c         Px         Py         Pz  ...        Phi  \\\n",
      "0         0    4.504823   3.657920   2.162449   1.495616  ...   0.533901   \n",
      "1         2   20.351711   0.083766  18.341993   8.817961  ...   1.566229   \n",
      "2         2   14.036757  -1.195308  -6.466243 -12.401188  ...  -1.753587   \n",
      "3         2    7.881490  -1.487775   4.785600   6.082963  ...   1.872210   \n",
      "4         4  117.569649 -70.163682 -19.713464  92.255403  ...  -2.867690   \n",
      "...     ...         ...        ...        ...        ...  ...        ...   \n",
      "5893   9988   30.088755 -12.425109  16.724781 -21.707868  ...   2.209748   \n",
      "5894   9991   69.372242  32.917326  20.269900 -57.602854  ...   0.551943   \n",
      "5895   9994   95.386077  15.883706   0.683463  94.051818  ...   0.043003   \n",
      "5896   9996   49.254200 -26.899839 -40.790642   6.204705  ...  -2.153794   \n",
      "5897   9999   21.780870  -8.663402 -13.227505 -14.979481  ...  -2.150646   \n",
      "\n",
      "           Eta  Dxy  Eem  Ehad  \n",
      "0     0.345078    0    0     0  \n",
      "1     0.463926    0    0     0  \n",
      "2    -1.391405    0    0     0  \n",
      "3     1.024774    0    0     0  \n",
      "4     1.057453    0    0     0  \n",
      "...        ...  ...  ...   ...  \n",
      "5893 -0.910686    0    0     0  \n",
      "5894 -1.189245    0    0     0  \n",
      "5895  2.477843    0    0     0  \n",
      "5896  0.126646    0    0     0  \n",
      "5897 -0.843647    0    0     0  \n",
      "\n",
      "[5898 rows x 13 columns]\n",
      "Elapse time: 7.32 seconds\n",
      "Extracting data from /data/shared/Delphes/ttbar_lepFilter_13TeV/ttbar_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['MuonTight.PT', 'MuonTight.Eta', 'MuonTight.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"['MuonTight.Charge'] -> ['PID', 'Charge']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Procedure at column 11 maps \"[] -> ['Eem', 'Ehad']\"\n",
      "Extracting Leaves: MuonTight.PT, MuonTight.Eta, MuonTight.Phi, MuonTight.Charge, MuonTight.PT, MuonTight.Phi, MuonTight.Eta\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[=================== ] 9759/10000      Entry         E/c          Px         Py         Pz  ...        Phi  \\\n",
      "0         4   59.010815   46.120717   3.749196  36.620870  ...   0.081113   \n",
      "1         5  117.993777  116.838144  11.555625 -11.740356  ...   0.098582   \n",
      "2         5   34.494549   27.188032   4.154507  20.818591  ...   0.151634   \n",
      "3         6   14.109672    4.727418 -13.267106   0.840885  ...  -1.228497   \n",
      "4         7   15.251995   -7.718261   8.475752  10.059933  ...   2.309453   \n",
      "...     ...         ...         ...        ...        ...  ...        ...   \n",
      "6196   9995   27.810670   10.276119  -8.757456  24.313176  ...  -0.705778   \n",
      "6197   9996   44.806177    7.100072 -10.413724 -42.996810  ...  -0.972390   \n",
      "6198   9997   83.172674   50.021760  28.988699  59.792654  ...   0.525226   \n",
      "6199   9998   73.684080   36.685436  51.594123 -37.703552  ...   0.952700   \n",
      "6200   9998   41.576047   34.727944 -22.825892   1.226820  ...  -0.581474   \n",
      "\n",
      "           Eta  Dxy  Eem  Ehad  \n",
      "0     0.725948    0    0     0  \n",
      "1    -0.099830    0    0     0  \n",
      "2     0.698690    0    0     0  \n",
      "3     0.059669    0    0     0  \n",
      "4     0.792100    0    0     0  \n",
      "...        ...  ...  ...   ...  \n",
      "6196  1.350815    0    0     0  \n",
      "6197 -1.941093    0    0     0  \n",
      "6198  0.905361    0    0     0  \n",
      "6199 -0.565020    0    0     0  \n",
      "6200  0.029517    0    0     0  \n",
      "\n",
      "[6201 rows x 13 columns]\n",
      "Elapse time: 7.47 seconds\n",
      "Extracting data from /data/shared/Delphes/ttbar_lepFilter_13TeV/ttbar_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['EFlowNeutralHadron.ET', 'EFlowNeutralHadron.Eta', 'EFlowNeutralHadron.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"[] -> ['PID']\"\n",
      "Procedure at column 6 maps \"[] -> ['Charge']\"\n",
      "Procedure at column 7 maps \"['EFlowNeutralHadron.ET'] -> ['PT']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Extracting Leaves: EFlowNeutralHadron.ET, EFlowNeutralHadron.Eta, EFlowNeutralHadron.Phi, EFlowNeutralHadron.ET, EFlowNeutralHadron.Phi, EFlowNeutralHadron.Eta, EFlowNeutralHadron.Eem, EFlowNeutralHadron.Ehad\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[===========         ] 5941/10000"
     ]
    }
   ],
   "source": [
    "for job in jobs:\n",
    "    doJob(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
