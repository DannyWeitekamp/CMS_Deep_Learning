{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#WARNING THIS SCRIPT TAKES A LONG TIME TO RUN!\n",
    "#Note Everythin is in natural units so C = 1\n",
    "import sys, os\n",
    "if __package__ is None:\n",
    "    import sys, os\n",
    "    sys.path.append(os.path.realpath(\"/data/shared/Software/\"))\n",
    "    sys.path.append(os.path.realpath(\"../../\"))\n",
    "from CMS_Deep_Learning.utils.data_parse import *\n",
    "#from CMS_Deep_Learning.utils.data_parse import leaves_from_obj\n",
    "import ROOT\n",
    "from ROOT import TTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import glob\n",
    "from itertools import cycle, islice\n",
    "import time\n",
    "\n",
    "#didit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cullNonObservables(frame):\n",
    "    #Status of 1 means that the particle is a stable product\n",
    "    stable_cond = frame[\"Status\"] == 1 \n",
    "    #All even leptons are neutrinos which we can't measure\n",
    "    notNeutrino_cond = frame[\"PID\"] % 2 == 1\n",
    "    parton_cond = np.abs(frame[\"PID\"]) <= 8\n",
    "    #Get all entries that satisfy the conditions\n",
    "    frame = frame[stable_cond & notNeutrino_cond]\n",
    "    #Drop the Status frame since we only needed it to see if the particle was stable\n",
    "    frame = frame.drop([\"Status\"], axis=1)\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "#http://stackoverflow.com/questions/3678869/pythonic-way-to-combine-two-lists-in-an-alternating-fashion\n",
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    pending = len(iterables)\n",
    "    nexts = cycle(iter(it).next for it in iterables)\n",
    "    while pending:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            pending -= 1\n",
    "            nexts = cycle(islice(nexts, pending))\n",
    "\n",
    "\n",
    "def storeAllUnjoined(filepath, outputdir, rerun=False):\n",
    "    lst = [         (\"NumValues\", \"getPandasNumValues(filepath)\"),\n",
    "                    (\"Photon\", \"getPandasPhotons(filepath)\"),\n",
    "                    (\"Electron\", \"getPandasElectrons(filepath)\"),\n",
    "                    (\"MuonTight\", \"getPandasTightMuons(filepath)\"),\n",
    "                    (\"MissingET\", \"getPandasMissingET(filepath)\"),\n",
    "                    (\"EFlowPhoton\", \"getPandasEFlowParticle(filepath, name='EFlowNeutralHadron')\"),\n",
    "                    (\"EFlowNeutralHadron\", \"getPandasEFlowParticle(filepath, name='EFlowPhoton')\"),\n",
    "                    (\"EFlowTrack\", \"getPandasEFlowTrack(filepath)\")]\n",
    "    \n",
    "    filename = os.path.splitext(ntpath.basename(filepath))[0]\n",
    "    out_file = outputdir + filename + \".h5\"\n",
    "    print(out_file)\n",
    "    store = pd.HDFStore(out_file)\n",
    "    keys = store.keys()\n",
    "    print(\"KEYS:\", keys)\n",
    "    for tup in lst:\n",
    "        if(rerun or ((\"/\"+tup[0]) in keys) == False):\n",
    "            #print(rerun, ~os.path.isfile(out_file), out_file)\n",
    "            frame = eval(tup[1])\n",
    "            print(frame)\n",
    "            store.put(tup[0], frame, format='table')\n",
    "            \n",
    "        \n",
    "\n",
    "def storeAllJoined(filepath, outputfile, rerun=False):\n",
    "    if(rerun or os.path.isfile(outputfile) == False):\n",
    "        #print(rerun, ~os.path.isfile(out_file), out_file)\n",
    "        frame = getPandasAll(filepath)\n",
    "        frame.to_hdf(outputfile, 'data', mode='w')\n",
    "    \n",
    "\n",
    "    \n",
    "def makeJobs(filename, job_types,\n",
    "             directory=\"/data/shared/Delphes/\",\n",
    "             unjoined_folder=\"/pandas_unjoined/\",\n",
    "             joined_folder=\"/pandas_joined/\"):\n",
    "    files = glob.glob(directory + filename + \"/*.root\")\n",
    "    unjoined_dir = directory + filename + unjoined_folder\n",
    "    joined_dir = directory + filename + joined_folder\n",
    "    if not os.path.exists(joined_dir):\n",
    "        os.makedirs(joined_dir)\n",
    "    if not os.path.exists(unjoined_dir):\n",
    "        os.makedirs(unjoined_dir)\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    for f in files:\n",
    "        f_name = os.path.splitext(ntpath.basename(f))[0]\n",
    "        for j_type in job_types:\n",
    "            if(j_type == \"unjoined\"):\n",
    "                jobs.append((j_type,f, unjoined_dir))\n",
    "            elif(j_type == \"joined\"):\n",
    "                jobs.append((j_type,f, joined_dir + f_name + \".h5\"))\n",
    "\n",
    "    return jobs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttbar_files = glob.glob(\"/data/shared/Delphes/ttbar_lepFilter_13TeV/*.root\")\n",
    "# WJet_files = glob.glob(\"/data/shared/Delphes/wjets_lepFilter_13TeV/*.root\")\n",
    "# WJet_files = glob.glob(\"/data/shared/Delphes/qcd_lepFilter_13TeV/*.root\")\n",
    "\n",
    "frame = getPandasNumValues(ttbar_files[0])\n",
    "#frame = getPandasEFlowParticle(ttbar_files[0])\n",
    "print(frame)\n",
    "#frame = getPandasEFlowParticle(ttbar_files[0], \"EFlowNeutralHadron\")\n",
    "#print(frame)\n",
    "#frame = getPandasEFlowTrack(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasPhotons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasElectrons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasTightMuons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasMissingET(ttbar_files[0])\n",
    "#print(frame)\n",
    "\n",
    "#ttbar_jobs = makeJobs(\"ttbar_lepFilter_13TeV\", [\"joined\"])\n",
    "#WJet_jobs = makeJobs(\"wjets_lepFilter_13TeV\", [\"joined\"])\n",
    "#qcd_jobs = makeJobs(\"qcd_lepFilter_13TeV\", [\"joined\"])\n",
    "ttbar_jobs = makeJobs(\"ttbar_lepFilter_13TeV\", [\"unjoined\"])\n",
    "WJet_jobs = makeJobs(\"wjets_lepFilter_13TeV\", [\"unjoined\"])\n",
    "qcd_jobs = makeJobs(\"qcd_lepFilter_13TeV\", [\"unjoined\"])\n",
    "    \n",
    "jobs = roundrobin(ttbar_jobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool\n",
    "# from multiprocessing import Process, Queue\n",
    "# import time\n",
    "\n",
    "def doJob(job):\n",
    "    if(job[0] == \"unjoined\"):\n",
    "        #print(\"Started: \", job[1])\n",
    "        storeAllUnjoined(job[1], job[2])\n",
    "    elif(job[0] == \"joined\"):\n",
    "        #print(job)\n",
    "        storeAllJoined(job[1], job[2])\n",
    "    return job[1]\n",
    "\n",
    "# pool = Pool(4)\n",
    "\n",
    "# def mycallback(x):\n",
    "#     print(\"Finished: \", x)\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "# results = []\n",
    "# for job in jobs:\n",
    "#     r = pool.apply_async(doJob, args=[job], callback=mycallback)\n",
    "#     results.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for job in jobs:\n",
    "#    doJob(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
