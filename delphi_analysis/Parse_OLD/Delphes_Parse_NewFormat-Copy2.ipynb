{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/04\n"
     ]
    }
   ],
   "source": [
    "#WARNING THIS SCRIPT TAKES A LONG TIME TO RUN!\n",
    "#Note Everythin is in natural units so C = 1\n",
    "import sys, os\n",
    "if __package__ is None:\n",
    "    import sys, os\n",
    "    sys.path.append(os.path.realpath(\"/data/shared/Software/\"))\n",
    "    sys.path.append(os.path.realpath(\"../../\"))\n",
    "from CMS_SURF_2016.utils.data_parse import ROOT_to_pandas\n",
    "from CMS_SURF_2016.utils.data_parse import DataProcessingProcedure\n",
    "from CMS_SURF_2016.utils.data_parse import leaves_from_obj\n",
    "import ROOT\n",
    "from ROOT import TTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import glob\n",
    "from itertools import cycle, islice\n",
    "\n",
    "#didit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cullNonObservables(frame):\n",
    "    #Status of 1 means that the particle is a stable product\n",
    "    stable_cond = frame[\"Status\"] == 1 \n",
    "    #All even leptons are neutrinos which we can't measure\n",
    "    notNeutrino_cond = frame[\"PID\"] % 2 == 1\n",
    "    parton_cond = np.abs(frame[\"PID\"]) <= 8\n",
    "    #Get all entries that satisfy the conditions\n",
    "    frame = frame[stable_cond & notNeutrino_cond]\n",
    "    #Drop the Status frame since we only needed it to see if the particle was stable\n",
    "    frame = frame.drop([\"Status\"], axis=1)\n",
    "    return frame\n",
    "\n",
    "#Define the speed of light C\n",
    "#Turns C=1 since everything is in natural units :/\n",
    "#C = np.float64(2.99792458e8); #m/s\n",
    "mass_of_electron = np.float64(0.0005109989461) #eV/c\n",
    "mass_of_muon = np.float64(0.1056583715)      #eV/c\n",
    "#def four_vec_func(inputs):\n",
    "#        E = inputs[0]\n",
    "#        Eta = inputs[1]\n",
    "#        Phi = inputs[2]\n",
    "#        PT = inputs[3]\n",
    "#        E_over_c = E/C\n",
    "#        px = E_over_c * np.sin(Phi) * np.cos(Eta) \n",
    "#        py = E_over_c * np.sin(Phi) * np.sin(Eta)\n",
    "#        pz = E_over_c * np.cos(Phi)\n",
    "#        print(np.sqrt(px*px + py*py), PT/C)\n",
    "#        return [E_over_c, px, py, pz]\n",
    "\n",
    "#def getPandasPhotons(filename):\n",
    "#    four_vec_inputs, dummy = leaves_from_obj(\"Photon\", [\"PT\", \"Eta\", \"Phi\"])\n",
    "#    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0), four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "\n",
    "#    PID_proc = DataProcessingProcedure(lambda x:[22], [], [\"PID\"])\n",
    "#    charge_proc = DataProcessingProcedure(lambda x:[0], [], [\"Charge\"])\n",
    "\n",
    "#    columns=[four_vec_proc, PID_proc, charge_proc]\n",
    "#    leaves, columns = leaves_from_obj(\"Photon\", columns+[\"PT\", \"Eta\", \"Phi\"])\n",
    "\n",
    "#    photon_frame = ROOT_to_pandas(filename,\n",
    "#                          leaves,\n",
    "#                          columns=columns,\n",
    "#                          verbosity=1)\n",
    "#    return photon_frame\n",
    "\n",
    "\n",
    "extra_data = [\"PT\", \"Phi\", \"Eta\"]\n",
    "dxy_proc = [DataProcessingProcedure(lambda x: [0], [], [\"Dxy\"])]\n",
    "elfow_proc = [DataProcessingProcedure(lambda x: [0,0], [], [\"Eem\", \"Ehad\"])]\n",
    "\n",
    "\n",
    "def four_vec_from_PT(inputs, M):\n",
    "    #print(type(inputs[0]))\n",
    "    PT = inputs[0] #Units ?\n",
    "    Eta = inputs[1]\n",
    "    Phi = inputs[2]\n",
    "    #M has units of eV/(c^2)\n",
    "    if(M == None):\n",
    "        M = inputs[3]\n",
    "    momentum_mag = PT * np.cosh(Eta)\n",
    "    #if(~didit):\n",
    "    #print(momentum_mag, PT, np.cosh(Eta))\n",
    "    #    didit = True\n",
    "    E_over_c = np.sqrt(np.square(M) + np.square(momentum_mag))\n",
    "    #print(PT/np.sin(Phi))\n",
    "    px = PT * np.cos(Phi) \n",
    "    py = PT * np.sin(Phi) \n",
    "    pz = PT * np.sinh(Eta)\n",
    "    return [E_over_c, px, py, pz]\n",
    "\n",
    "def getPandasParticles(filename, cull=True):\n",
    "    #C=1 in natural units so no processing needs to be done\n",
    "    E_over_c_proc = DataProcessingProcedure(lambda x:x[0], [\"Particle.E\"], [\"E/c\"])\n",
    "    columns= [E_over_c_proc, \"Px\", \"Py\", \"Pz\", \"PID\", \"Charge\"]#, \"Status\"]\n",
    "    leaves, columns = leaves_from_obj(\"Particle\", columns+extra_data + dxy_proc + elfow_proc)\n",
    "    original_frame = ROOT_to_pandas(filename,\n",
    "                                 leaves,\n",
    "                                  columns=columns,\n",
    "                                  verbosity=1)\n",
    "    if(cull):\n",
    "        particle_frame = cullNonObservables(original_frame)\n",
    "    else:\n",
    "        particle_frame = original_frame\n",
    "    return particle_frame\n",
    "\n",
    "\n",
    "def getPandasSpecificParticles(filename, name, mass=None, pid=None, chrg_def=-1, charge=None):\n",
    "    if(mass != None):\n",
    "        four_vec_inputs, dummy = leaves_from_obj(name, [\"PT\", \"Eta\", \"Phi\"])\n",
    "    else:\n",
    "        four_vec_inputs, dummy = leaves_from_obj(name, [\"PT\", \"Eta\", \"Phi\", \"Mass\"])\n",
    "        \n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,mass)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    \n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    \n",
    "    if(charge == None):\n",
    "        if(pid != None):\n",
    "            PID_charge_proc = DataProcessingProcedure(lambda x: [pid*chrg_def*x[0], x[0]]\n",
    "                                                      , [name + \".Charge\"], [\"PID\", \"Charge\"])\n",
    "            columns=[four_vec_proc, PID_charge_proc]#, status_proc]\n",
    "        else:\n",
    "            columns=[four_vec_proc, \"PID\", \"Charge\"]#, status_proc]\n",
    "    else:\n",
    "        charge_proc = DataProcessingProcedure(lambda x: [charge], [], [\"Charge\"])\n",
    "        if(pid != None):\n",
    "            PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "            columns=[four_vec_proc, PID_proc, charge_proc]#,status_proc]\n",
    "        else:\n",
    "            columns=[four_vec_proc, \"PID\", charge_proc]#,status_proc]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    leaves, columns = leaves_from_obj(name, columns+extra_data + dxy_proc + elfow_proc)\n",
    "\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "\n",
    "def getPandasPhotons(filename):\n",
    "    return getPandasSpecificParticles(filename, \"Photon\", mass=0, pid=22, charge=0)\n",
    "\n",
    "def getPandasElectrons(filename):\n",
    "    return getPandasSpecificParticles(filename, \"Electron\", mass=mass_of_electron, pid=11)\n",
    "\n",
    "def getPandasTightMuons(filename):\n",
    "    return getPandasSpecificParticles(filename, \"MuonTight\", mass=mass_of_muon, pid=13)\n",
    "\n",
    "def getPandasJets(filename):\n",
    "    return getPandasSpecificParticles(filename, \"Jet\", pid=100, chrg_def=1)\n",
    "\n",
    "def getPandasMissingET(filename, name=\"MissingET\"):  \n",
    "    pid = 83\n",
    "    if(name == \"PuppiMissingET\"): pid=84\n",
    "    four_vec_inputs, dummy = leaves_from_obj(name, [\"MET\", \"Eta\", \"Phi\"])\n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    charge_proc = DataProcessingProcedure(lambda x: [0], [], [\"Charge\"])\n",
    "    PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "    columns=[four_vec_proc, PID_proc, charge_proc]#, status_proc]\n",
    "    met_proc = DataProcessingProcedure(lambda x: [x[0]], [\"MissingET.MET\"], [\"PT\"] )\n",
    "    \n",
    "    ex = [x if (x != \"PT\") else met_proc for x in extra_data]\n",
    "    leaves, columns = leaves_from_obj(name, columns+ex + dxy_proc + elfow_proc)\n",
    "\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "def getPandasEFlowParticle(filename, name=\"EFlowPhoton\"):  \n",
    "    pid = 90\n",
    "    if(name == \"EFlowNeutralHadron\"): pid=91\n",
    "    four_vec_inputs, dummy = leaves_from_obj(name, [\"ET\", \"Eta\", \"Phi\"])\n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    charge_proc = DataProcessingProcedure(lambda x: [0], [], [\"Charge\"])\n",
    "    PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "    columns=[four_vec_proc, PID_proc, charge_proc]#, status_proc]\n",
    "    \n",
    "    \n",
    "    et_proc = DataProcessingProcedure(lambda x: [x[0]], [name+\".ET\"], [\"PT\"] )\n",
    "    \n",
    "    ex = [x if (x != \"PT\") else et_proc for x in extra_data]\n",
    "    leaves, columns = leaves_from_obj(name, columns+ex + dxy_proc + [\"Eem\", \"Ehad\"])\n",
    "\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "\n",
    "def getPandasEFlowTrack(filename):  \n",
    "    pid = 89\n",
    "    four_vec_inputs, dummy = leaves_from_obj(\"EFlowTrack\", [\"PT\", \"Eta\", \"Phi\"])\n",
    "    four_vec_proc = DataProcessingProcedure(lambda x: four_vec_from_PT(x,0)\n",
    "                                            , four_vec_inputs, [\"E/c\", \"Px\",\"Py\",\"Pz\"])\n",
    "    #status_proc = DataProcessingProcedure(lambda x:[1], [], [\"Status\"])\n",
    "    #charge_proc = DataProcessingProcedure(lambda x: [0], [], [\"Charge\"])\n",
    "    PID_proc = DataProcessingProcedure(lambda x: [pid], [], [\"PID\"])\n",
    "    columns=[four_vec_proc, PID_proc, \"Charge\"]#, status_proc]\n",
    "    \n",
    "    \n",
    "    #et_proc = DataProcessingProcedure(lambda x: [x[0]], [name+\".ET\"], [\"PT\"] )\n",
    "    \n",
    "    #ex = [x if (x != \"PT\") else et_proc for x in extra_data]\n",
    "    leaves, columns = leaves_from_obj(\"EFlowTrack\", columns+extra_data + [\"Dxy\"] + elfow_proc)\n",
    "    print(leaves, columns)\n",
    "    #Extract the tables from the root file\n",
    "    frame = ROOT_to_pandas(filename,\n",
    "                          leaves,\n",
    "                          columns=columns,\n",
    "                          verbosity=1)\n",
    "    return frame\n",
    "\n",
    "\n",
    "#def getPandasAll(filename, cull=False, includePuppi=True):\n",
    "#    lst = [getPandasPhotons(filename),\n",
    "#                    getPandasElectrons(filename),\n",
    "#                    getPandasTightMuons(filename),\n",
    "#                    getPandasJets(filename),\n",
    "#                    getPandasParticles(filename, cull=cull),\n",
    "#                    getPandasMissingET(filename)]\n",
    "#    \n",
    "#    if(includePuppi):\n",
    "#        lst = lst + [getPandasMissingET(filename, \"PuppiMissingET\")]\n",
    "#    #Merge all these frames\n",
    "#    out = pd.concat(lst)\n",
    "#    return out\n",
    "\n",
    "def getPandasAll(filename, cull=False, includePuppi=False):\n",
    "    lst = [getPandasPhotons(filename),\n",
    "                    getPandasElectrons(filename),\n",
    "                    getPandasTightMuons(filename),\n",
    "                    getPandasEFlowParticle(filename, name=\"EFlowNeutralHadron\"),\n",
    "                    getPandasEFlowParticle(filename, name=\"EFlowPhoton\"),\n",
    "                    getPandasEFlowTrack(filename),\n",
    "                    getPandasMissingET(filename)]\n",
    "    \n",
    "    if(includePuppi):\n",
    "        lst = lst + [getPandasMissingET(filename, \"PuppiMissingET\")]\n",
    "    #Merge all these frames\n",
    "    out = pd.concat(lst)\n",
    "    return out\n",
    "\n",
    "#def getPandasAll(filename):\n",
    "#    out = pd.concat([getPandasPhotons(filename),getPandasParticles(filename, cull=False)])\n",
    "#    return out\n",
    "\n",
    "#http://stackoverflow.com/questions/3678869/pythonic-way-to-combine-two-lists-in-an-alternating-fashion\n",
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    pending = len(iterables)\n",
    "    nexts = cycle(iter(it).next for it in iterables)\n",
    "    while pending:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            pending -= 1\n",
    "            nexts = cycle(islice(nexts, pending))\n",
    "\n",
    "    \n",
    "def storeAllUnjoined(filepath, outputDir, rerun=False):\n",
    "    \n",
    "    filename = os.path.splitext(ntpath.basename(filepath))[0]\n",
    "    \n",
    "    name_cols = [(\"EFlowTrack\", [\"PT\", \"Eta\", \"Phi\", \"Dxy\", \"Charge\"]),\n",
    "                 (\"EFlowPhoton\", [\"ET\", \"Eta\", \"Phi\", \"Eem\", \"Ehad\"]),\n",
    "                 (\"EFlowNeutralHadron\", [\"ET\", \"Eta\", \"Phi\", \"Eem\", \"Ehad\"]),\n",
    "                 (\"Electron\", [\"PT\", \"Eta\", \"Phi\", \"Charge\"]),\n",
    "                 (\"MuonTight\", [\"PT\", \"Eta\", \"Phi\", \"Charge\"]),\n",
    "                 (\"MissingET\", [\"MET\", \"Eta\", \"Phi\"])]\n",
    "    for nc in name_cols:\n",
    "        name = nc[0]\n",
    "        cols = nc[1]\n",
    "        out_file = outputDir + name + \"/\" + filename + \".h5\"\n",
    "        leaves, columns = leaves_from_obj(name,cols)\n",
    "        if not os.path.exists(outputDir+name):\n",
    "            os.makedirs(outputDir+name)\n",
    "        if(rerun or os.path.isfile(out_file) == False):\n",
    "            #print(rerun, ~os.path.isfile(out_file), out_file)\n",
    "            frame = ROOT_to_pandas(filepath, leaves, columns=columns)\n",
    "            frame.to_hdf(out_file, 'data', mode='w')\n",
    "\n",
    "def storeAllJoined(filepath, outputfile, rerun=False):\n",
    "    if(rerun or os.path.isfile(outputfile) == False):\n",
    "        #print(rerun, ~os.path.isfile(out_file), out_file)\n",
    "        frame = getPandasAll(filepath)\n",
    "        frame.to_hdf(outputfile, 'data', mode='w')\n",
    "    \n",
    "\n",
    "    \n",
    "def makeJobs(filename, job_types,\n",
    "             directory=\"/data/shared/Delphes/\",\n",
    "             unjoined_folder=\"/pandas_unjoined/\",\n",
    "             joined_folder=\"/pandas_joined/\"):\n",
    "    files = glob.glob(directory + filename + \"/*.root\")\n",
    "    unjoined_dir = directory + filename + unjoined_folder\n",
    "    joined_dir = directory + filename + joined_folder\n",
    "    if not os.path.exists(joined_dir):\n",
    "        os.makedirs(joined_dir)\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    for f in files:\n",
    "        f_name = os.path.splitext(ntpath.basename(f))[0]\n",
    "        for j_type in job_types:\n",
    "            if(j_type == \"unjoined\"):\n",
    "                jobs.append((j_type,f, unjoined_dir))\n",
    "            elif(j_type == \"joined\"):\n",
    "                jobs.append((j_type,f, joined_dir + f_name + \".h5\"))\n",
    "\n",
    "    return jobs\n",
    "    \n",
    "    \n",
    "#def groupEntriesToArrays(frame, select):\n",
    "#    out = []\n",
    "#    m = frame['Entry'].max()\n",
    "#    for entry in range(0, m+1):\n",
    "#        cond = frame['Entry'] == entry\n",
    "#        entry_frame = frame[cond]\n",
    "#        entry_frame = entry_frame[select]\n",
    "#        arr = np.array(entry_frame)\n",
    "#        np.random.shuffle(arr)\n",
    "#        out.append(arr)\n",
    "#    return out\n",
    "\n",
    "#def groupEntriesToArrays(frame, select):\n",
    "#    grouped = frame.groupby([\"Entry\"]).apply(lambda df: df[select].tolist())\n",
    "    #print(grouped)\n",
    "#    return grouped\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttbar_files = glob.glob(\"/data/shared/Delphes/ttbar_lepFilter_13TeV/*.root\")\n",
    "# WJet_files = glob.glob(\"/data/shared/Delphes/wjets_lepFilter_13TeV/*.root\")\n",
    "# WJet_files = glob.glob(\"/data/shared/Delphes/qcd_lepFilter_13TeV/*.root\")\n",
    "\n",
    "#frame = getPandasEFlowParticle(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasEFlowParticle(ttbar_files[0], \"EFlowNeutralHadron\")\n",
    "#print(frame)\n",
    "#frame = getPandasEFlowTrack(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasPhotons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasElectrons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasTightMuons(ttbar_files[0])\n",
    "#print(frame)\n",
    "#frame = getPandasMissingET(ttbar_files[0])\n",
    "#print(frame)\n",
    "\n",
    "ttbar_jobs = makeJobs(\"ttbar_lepFilter_13TeV\", [\"joined\"])\n",
    "WJet_jobs = makeJobs(\"wjets_lepFilter_13TeV\", [\"joined\"])\n",
    "qcd_jobs = makeJobs(\"qcd_lepFilter_13TeV\", [\"joined\"])\n",
    "#ttbar_jobs = makeJobs(\"ttbar_lepFilter_13TeV\", [\"unjoined\"])\n",
    "#WJet_jobs = makeJobs(\"wjets_lepFilter_13TeV\", [\"unjoined\"])\n",
    "#qcd_jobs = makeJobs(\"qcd_lepFilter_13TeV\", [\"unjoined\"])\n",
    "    \n",
    "jobs = roundrobin(WJet_jobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool\n",
    "# from multiprocessing import Process, Queue\n",
    "# import time\n",
    "\n",
    "def doJob(job):\n",
    "    if(job[0] == \"unjoined\"):\n",
    "        print(\"Started: \", job[1])\n",
    "        #storeAllUnjoined(job[1], job[2])\n",
    "    elif(job[0] == \"joined\"):\n",
    "        #print(job)\n",
    "        storeAllJoined(job[1], job[2])\n",
    "    return job[1]\n",
    "\n",
    "# pool = Pool(4)\n",
    "\n",
    "# def mycallback(x):\n",
    "#     print(\"Finished: \", x)\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "# results = []\n",
    "# for job in jobs:\n",
    "#     r = pool.apply_async(doJob, args=[job], callback=mycallback)\n",
    "#     results.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from /data/shared/Delphes/wjets_lepFilter_13TeV/wjets_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['Photon.PT', 'Photon.Eta', 'Photon.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"[] -> ['PID']\"\n",
      "Procedure at column 6 maps \"[] -> ['Charge']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Procedure at column 11 maps \"[] -> ['Eem', 'Ehad']\"\n",
      "Extracting Leaves: Photon.PT, Photon.Eta, Photon.Phi, Photon.PT, Photon.Phi, Photon.Eta\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[=================== ] 9961/10000      Entry         E/c         Px         Py          Pz  ...        Phi  \\\n",
      "0         4  312.670955  22.408879 -10.771771 -311.680826  ...  -0.448082   \n",
      "1        10   10.239202   1.689869  10.046479   -1.026581  ...   1.404151   \n",
      "2        11  351.284899 -18.375614  14.749910 -350.493734  ...   2.465214   \n",
      "3        14   16.959497 -16.118540  -2.885056    4.415162  ...  -2.964478   \n",
      "4        20  126.474599  40.404224   5.356522  119.727317  ...   0.131805   \n",
      "...     ...         ...        ...        ...         ...  ...        ...   \n",
      "1622   9938   10.226795   6.382005   7.960693    0.696202  ...   0.895026   \n",
      "1623   9940   41.367735 -35.123409 -16.591572   14.225168  ...  -2.700285   \n",
      "1624   9962   42.911191  15.030531  -7.992775   39.389961  ...  -0.488739   \n",
      "1625   9989  447.798024 -16.098290   5.566063 -447.473949  ...   2.808705   \n",
      "1626   9996   17.022843   5.173158  14.352019    7.552165  ...   1.224844   \n",
      "\n",
      "           Eta  Dxy  Eem  Ehad  \n",
      "0    -3.223317    0    0     0  \n",
      "1    -0.100598    0    0     0  \n",
      "2    -3.393933    0    0     0  \n",
      "3     0.266468    0    0     0  \n",
      "4     1.798506    0    0     0  \n",
      "...        ...  ...  ...   ...  \n",
      "1622  0.068182    0    0     0  \n",
      "1623  0.358476    0    0     0  \n",
      "1624  1.575787    0    0     0  \n",
      "1625 -3.961953    0    0     0  \n",
      "1626  0.476765    0    0     0  \n",
      "\n",
      "[1627 rows x 13 columns]\n",
      "Elapse time: 7.70 seconds\n",
      "Extracting data from /data/shared/Delphes/wjets_lepFilter_13TeV/wjets_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['Electron.PT', 'Electron.Eta', 'Electron.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"['Electron.Charge'] -> ['PID', 'Charge']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Procedure at column 11 maps \"[] -> ['Eem', 'Ehad']\"\n",
      "Extracting Leaves: Electron.PT, Electron.Eta, Electron.Phi, Electron.Charge, Electron.PT, Electron.Phi, Electron.Eta\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[==================  ] 9297/10000      Entry         E/c         Px         Py          Pz  ...        Phi  \\\n",
      "0         3  162.996215 -12.628056 -14.620879 -161.847237  ...  -2.283190   \n",
      "1         8  261.637856 -10.302695 -45.446967  257.454453  ...  -1.793725   \n",
      "2        24   53.994053  37.742683 -17.838290  -34.243876  ...  -0.441512   \n",
      "3        37  108.194156  19.795138  33.020091 -101.112815  ...   1.030754   \n",
      "4        38  228.138685 -12.061979 -34.355512 -225.214269  ...  -1.908445   \n",
      "...     ...         ...        ...        ...         ...  ...        ...   \n",
      "2743   9979   34.468535 -10.406216 -32.860088    0.072070  ...  -1.877487   \n",
      "2744   9981   43.590260 -33.953655 -10.975204  -25.036074  ...  -2.828953   \n",
      "2745   9986  571.130909   8.112487  32.069780 -570.172107  ...   1.323030   \n",
      "2746   9990   51.609172  39.577512  -6.271480   32.523771  ...  -0.157154   \n",
      "2747   9992   33.116674  21.104446  -3.215335  -25.317545  ...  -0.151191   \n",
      "\n",
      "           Eta  Dxy  Eem  Ehad  \n",
      "0    -2.822235    0    0     0  \n",
      "1     2.410478    0    0     0  \n",
      "2    -0.748437    0    0     0  \n",
      "3    -1.693169    0    0     0  \n",
      "4    -2.521788    0    0     0  \n",
      "...        ...  ...  ...   ...  \n",
      "2743  0.002091    0    0     0  \n",
      "2744 -0.653990    0    0     0  \n",
      "2745 -3.540998    0    0     0  \n",
      "2746  0.741737    0    0     0  \n",
      "2747 -1.006945    0    0     0  \n",
      "\n",
      "[2748 rows x 13 columns]\n",
      "Elapse time: 6.04 seconds\n",
      "Extracting data from /data/shared/Delphes/wjets_lepFilter_13TeV/wjets_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['MuonTight.PT', 'MuonTight.Eta', 'MuonTight.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"['MuonTight.Charge'] -> ['PID', 'Charge']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Procedure at column 11 maps \"[] -> ['Eem', 'Ehad']\"\n",
      "Extracting Leaves: MuonTight.PT, MuonTight.Eta, MuonTight.Phi, MuonTight.Charge, MuonTight.PT, MuonTight.Phi, MuonTight.Eta\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[==================  ] 9297/10000      Entry         E/c         Px         Py          Pz  ...        Phi  \\\n",
      "0         2  125.614531  43.899635 -15.851040  116.621464  ...  -0.346507   \n",
      "1         5   71.496157  -3.204905 -49.702052   51.294482  ...  -1.635190   \n",
      "2         6  108.574155  49.371709  -6.494543   96.481041  ...  -0.130793   \n",
      "3         9   33.903393   0.495809  17.611121  -28.966040  ...   1.542651   \n",
      "4        12   34.090545  28.856175  -2.539550   17.972924  ...  -0.087781   \n",
      "...     ...         ...        ...        ...         ...  ...        ...   \n",
      "2495   9993   37.712577 -14.955953  -2.537252   34.526934  ...  -2.973544   \n",
      "2496   9996  115.716804  30.783246 -15.426433 -110.475266  ...  -0.464552   \n",
      "2497   9997   65.766567  20.251850  -5.902480  -62.291681  ...  -0.283598   \n",
      "2498   9998   47.668604   1.390323 -33.087784  -34.286297  ...  -1.528802   \n",
      "2499   9999   29.317083 -19.818570   7.009657   20.434510  ...   2.801633   \n",
      "\n",
      "           Eta  Dxy  Eem  Ehad  \n",
      "0     1.646732    0    0     0  \n",
      "1     0.902359    0    0     0  \n",
      "2     1.415323    0    0     0  \n",
      "3    -1.272131    0    0     0  \n",
      "4     0.586279    0    0     0  \n",
      "...        ...  ...  ...   ...  \n",
      "2495  1.560689    0    0     0  \n",
      "2496 -1.882389    0    0     0  \n",
      "2497 -1.803474    0    0     0  \n",
      "2498 -0.906121    0    0     0  \n",
      "2499  0.861484    0    0     0  \n",
      "\n",
      "[2500 rows x 13 columns]\n",
      "Elapse time: 6.04 seconds\n",
      "Extracting data from /data/shared/Delphes/wjets_lepFilter_13TeV/wjets_lepFilter_13TeV_1.root\n",
      "Using trees: Delphes\n",
      "Procedure at column 1 maps \"['EFlowNeutralHadron.ET', 'EFlowNeutralHadron.Eta', 'EFlowNeutralHadron.Phi'] -> ['E/c', 'Px', 'Py', 'Pz']\"\n",
      "Procedure at column 5 maps \"[] -> ['PID']\"\n",
      "Procedure at column 6 maps \"[] -> ['Charge']\"\n",
      "Procedure at column 7 maps \"['EFlowNeutralHadron.ET'] -> ['PT']\"\n",
      "Procedure at column 10 maps \"[] -> ['Dxy']\"\n",
      "Extracting Leaves: EFlowNeutralHadron.ET, EFlowNeutralHadron.Eta, EFlowNeutralHadron.Phi, EFlowNeutralHadron.ET, EFlowNeutralHadron.Phi, EFlowNeutralHadron.Eta, EFlowNeutralHadron.Eem, EFlowNeutralHadron.Ehad\n",
      "Renaming to: E/c, Px, Py, Pz, PID, Charge, PT, Phi, Eta, Dxy, Eem, Ehad\n",
      "[=============       ] 6668/10000"
     ]
    }
   ],
   "source": [
    "for job in jobs:\n",
    "    doJob(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
