{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "if __package__ is None:\n",
    "    import sys, os\n",
    "    sys.path.append(os.path.realpath(\"/data/shared/Software/\"))\n",
    "from CMS_Deep_Learning.storage.archiving import *\n",
    "from CMS_Deep_Learning.layers.slice import Slice\n",
    "from CMS_Deep_Learning.layers.lorentz import Lorentz\n",
    "from keras.utils.visualize_util import plot\n",
    "from IPython.display import Image, display\n",
    "from CMS_Deep_Learning.postprocessing.colors import colors_contrasting\n",
    "from CMS_Deep_Learning.postprocessing.analysistools import *\n",
    "from CMS_Deep_Learning.postprocessing.plot import *\n",
    "from CMS_Deep_Learning.postprocessing.metrics import *\n",
    "import numpy as np\n",
    "archive_dir = \"/data/shared/Delphes/keras_archive/\"\n",
    "\n",
    "#def sortTrialsOn(lst):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (1d645dbd33ca1a4ec695e8cc49d4a4b6f848efda)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 4:14:32\n",
      "        val_acc = 0.7873\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'qcd', u'ttbar'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = Eta, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (0131079e4a5cbf5fba3ddcfbf3182f8e10c4fb17)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 6:41:01\n",
      "        val_acc = 0.8388\n",
      "        num_train = 225000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'ttbar', u'wjet', u'qcd'], lstm_dropout = 0.0, num_val = 225000, output_activation = softmax, patience = 8, query = None, sort_on = Eta, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (34d360fa4fc175ce772dd0c5a8eeb2fa94ad2a09)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 4:10:18\n",
      "        val_acc = 0.7734\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'qcd', u'ttbar'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = PT_ET, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (acef7a8ef2cece71de45291359598bc17e25b922)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 3:41:09\n",
      "        val_acc = 0.9670\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'ttbar', u'wjet'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = Eta, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (4072f34609af26d52ec9b7602ce1746bdf3b6db5)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 6:26:29\n",
      "        val_acc = 0.8317\n",
      "        num_train = 225000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'ttbar', u'wjet', u'qcd'], lstm_dropout = 0.0, num_val = 225000, output_activation = softmax, patience = 8, query = None, sort_on = Phi, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (bb89ffd567fd226588695fdccea5898e6d6a866e)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 6:41:05\n",
      "        val_acc = 0.8263\n",
      "        num_train = 225000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'ttbar', u'wjet', u'qcd'], lstm_dropout = 0.0, num_val = 225000, output_activation = softmax, patience = 8, query = None, sort_on = PT_ET, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (6a2b9a7ef5a847753120bba63ea82f0b06093826)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 4:13:55\n",
      "        val_acc = 0.9796\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'qcd', u'wjet'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = Phi, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (bd5fdd2d0fe7ce45d78ddfa74d3825021dc724e9)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 3:53:40\n",
      "        val_acc = 0.9706\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'ttbar', u'wjet'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = Phi, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (3d345c7fd4672e29e52e82f2aef0705d9fd063f7)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 2:02:18\n",
      "        val_acc = 0.9660\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'qcd', u'wjet'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = PT_ET, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (6555455ea5ba32f164e57c7b4e81fbd4a08c3a42)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 4:12:57\n",
      "        val_acc = 0.6881\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'qcd', u'ttbar'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = Phi, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (b9f4c17020065b45203a9bc6ca3ac7da4553b22a)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 2:34:55\n",
      "        val_acc = 0.9798\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'qcd', u'wjet'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = Eta, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (f6d0572b3f72fbd228eb0b13a44f6499cf5c4101)\n",
      "    Record_Info:\n",
      "        name = [u'LSTM'], elapse_time = 4:51:13\n",
      "        val_acc = 0.9626\n",
      "        num_train = 150000\n",
      "        activation = tanh, depth = 1, dropout = 0.0, labels = [u'ttbar', u'wjet'], lstm_dropout = 0.0, num_val = 150000, output_activation = softmax, patience = 8, query = None, sort_on = PT_ET, useObjTypeColumn = True\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "TRIAL SUMMARY (381915c32564add6ccfdebf7d3ca6a4d6d8efae6)\n",
      "    Record_Info:\n",
      "        name = [u'trial', u'LSTM'], elapse_time = 4:09:56, fit_cycles = 1\n",
      "        val_acc = 0.7833\n",
      "        num_train = 225000, num_validation = 60000\n",
      "        Non_MPI = True, activation = tanh, depth = 1, dropout = 0.0, labels = [u'ttbar', u'wjet', u'qcd'], lstm_dropout = 0.0, output_activation = softmax, patience = 8, query = None, sort_on = Phi, useObjTypeColumn = True, val_acc_ = 0.783292921926, val_acc_error = 0.00166886233478\n",
      "--------------------------------------------------\n",
      "('TotalNumber of Trials:', 13)\n"
     ]
    }
   ],
   "source": [
    "trials = get_trials_by_name(\"LSTM\", archive_dir)\n",
    "#trials = findWithMetrics(trials, {\"useObjTypeColumn\" : True})\n",
    "trials = [t for t in trials if t.is_complete()]\n",
    "for trial in trials:\n",
    "    trial.summary(showTraining=False,showValidation=False, showFit=False, showCompilation=False)\n",
    "print(\"TotalNumber of Trials:\", len(trials)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataProcedure results '3d5a9733451c92cb0218483c196cbfdddbfef850' read from archive\n",
      "DataProcedure results '3d5a9733451c92cb0218483c196cbfdddbfef850' read from archive\n",
      "(40000, 0)\n",
      "(40000, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9b8ee7312943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Slice\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSlice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Lorentz\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLorentz\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-9b8ee7312943>\u001b[0m in \u001b[0;36mgetError\u001b[1;34m(model, data, num_samples, custom_objects, ignoreAssert)\u001b[0m\n\u001b[0;32m    188\u001b[0m                             num_samples=num_samples, accumilate=accum)\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[0mbatch_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdItr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mbatch_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9b8ee7312943>\u001b[0m in \u001b[0;36masList\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumilate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                     \u001b[0macc_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from CMS_Deep_Learning.storage.archiving import DataProcedure\n",
    "if(sys.version_info[0] > 2):\n",
    "    from inspect import signature\n",
    "    getNumParams = lambda f: len(signature(f).parameters)\n",
    "else:\n",
    "    from inspect import getargspec\n",
    "    getNumParams = lambda f: len(getargspec(f)[0])\n",
    "\n",
    "\n",
    "class DataIterator:\n",
    "    def __init__(self, proc, num_samples=None, return_X=False, return_Y=True, accumilate=None, prediction_model=None):\n",
    "        if (isinstance(proc, list)):\n",
    "            first_data = proc[0].getData()\n",
    "        else:\n",
    "            first_data = proc.getData()\n",
    "        if (isinstance(first_data, types.GeneratorType)):\n",
    "            proc = first_data\n",
    "\n",
    "        self.proc = proc\n",
    "        self.num_samples = num_samples\n",
    "        self.accumilate = accumilate\n",
    "        self.prediction_model = prediction_model\n",
    "        self.return_X = return_X\n",
    "        self.return_Y = return_Y\n",
    "        if (isinstance(proc, list)):\n",
    "            if (False in [isinstance(p, DataProcedure) for p in proc]):\n",
    "                raise ValueError(\"procedure list must contain only DataProcedures\")\n",
    "            # self.next = _listNext\n",
    "            self.proc_itr = iter(self.proc)\n",
    "            self.mode = \"list\"\n",
    "        elif (isinstance(proc, types.GeneratorType)):\n",
    "            if (num_samples == None):\n",
    "                raise ValueError(\"num_samples must be passed along with procedure generator.\")\n",
    "            # self.next = _genNext\n",
    "            self.mode = \"generator\"\n",
    "        else:\n",
    "            raise ValueError(\"Bad input.\")\n",
    "            # initialize(proc, num_samples=num_samples, accumilate=accumilate, prediction_model=prediction_model)\n",
    "\n",
    "    def getLength(self):\n",
    "        if (self.num_samples == None):\n",
    "            num_samples = 0\n",
    "            for p in self.proc:\n",
    "                if (isinstance(p, DataProcedure)):\n",
    "                    X, Y = p.getData()\n",
    "                else:\n",
    "                    X, Y = p\n",
    "                if (not isinstance(Y, list)): Y = [Y]\n",
    "                num_samples += Y[0].shape[0]\n",
    "            self.num_samples = num_samples\n",
    "        return self.num_samples\n",
    "\n",
    "    def asList(self):\n",
    "        if (self.accumilate != None): num_params  =getNumParams(self.accumilate)\n",
    "        X_out = None\n",
    "        Y_out = None\n",
    "        pred_out = None\n",
    "        acc_out = None\n",
    "        pos = 0\n",
    "        for p in self.proc:\n",
    "            X, Y = p.getData()\n",
    "\n",
    "            if (not isinstance(Y, list)): Y = [Y]\n",
    "            L = Y[0].shape[0]\n",
    "\n",
    "            if (not isinstance(X, list)): X = [X]\n",
    "            if (self.return_X):\n",
    "                if (X_out == None): X_out = [[None] * self.getLength() for i in range(len(X))]\n",
    "                # print([len(x) for x in X_out])\n",
    "                # print([len(x) for x in X])\n",
    "                for i, x in enumerate(X):\n",
    "                    Xi_out = X_out[i]\n",
    "                    # print(len(xi))\n",
    "                    for j in range(L):\n",
    "                        Xi_out[pos + j] = x[j]\n",
    "\n",
    "            if (self.return_Y):\n",
    "                if (Y_out == None): Y_out = [[None] * self.getLength() for i in range(len(Y))]\n",
    "                for i, y in enumerate(Y):\n",
    "                    Yi_out = Y_out[i]\n",
    "                    for j in range(L):\n",
    "                        Yi_out[pos + j] = y[j]\n",
    "\n",
    "            if (self.prediction_model != None):\n",
    "                if (pred_out == None): pred_out = [None] * self.getLength()\n",
    "                pred = self.prediction_model.predict_on_batch(X)\n",
    "                for j in range(L):\n",
    "                    pred_out[pos + j] = pred[j]\n",
    "\n",
    "            if (self.accumilate != None):\n",
    "                if (acc_out == None): acc_out = [None] * self.getLength()\n",
    "                if(num_params == 1):\n",
    "                    acc = self.accumilate(X)\n",
    "                else:\n",
    "                    acc = self.accumilate(X,Y)\n",
    "                for j in range(L):\n",
    "                    acc_out[pos + j] = acc[j]\n",
    "                    print(len(acc_out),pos + j)\n",
    "\n",
    "            pos += L\n",
    "            print(pos, self.accumilate)  # ,acc_out))\n",
    "        out = []\n",
    "        if (X_out != None):\n",
    "            for i, xo in enumerate(X_out):\n",
    "                X_out[i] = np.array(xo)\n",
    "            out.append(X_out)\n",
    "        if (Y_out != None):\n",
    "            for i, yo in enumerate(Y_out):\n",
    "                Y_out[i] = np.array(yo)\n",
    "            out.append(Y_out)\n",
    "        if (pred_out != None):\n",
    "            out.append(np.array(pred_out))\n",
    "        if (acc_out != None):\n",
    "            out.append(np.array(acc_out))\n",
    "        return out\n",
    "\n",
    "    # def _genNext():\n",
    "    #    #N = num_samples/ba\n",
    "    #    data = data.getData()\n",
    "    #    for i in range(self.num_samples)\n",
    "    #        yield next(data)\n",
    "    #    return StopIteration()\n",
    "    '''\n",
    "    def _listNext():\n",
    "        for p in self.proc:\n",
    "            X,Y = p.getData()\n",
    "            pred = self.prediction_model.predict_on_batch(X) if self.prediction_model != None else None\n",
    "            acc = self.accumilate(X) if self.accumilate != None else None\n",
    "            for  in\n",
    "                yield next(self.proc)\n",
    "        return StopIteration()\n",
    "    '''\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "        # def next(self):\n",
    "        #    self.count += 1\n",
    "        #    if(self.mode == 0):\n",
    "\n",
    "\n",
    "class TrialIterator(DataIterator):\n",
    "    def __init__(self, trial, data_type=\"val\", return_X=False, return_Y=True, accumilate=None, return_prediction=False,\n",
    "                 custom_objects={}):\n",
    "        if (data_type == \"val\"):\n",
    "            proc = [DataProcedure.from_json(trial.archive_dir, t) for t in trial.val_procedure]\n",
    "            num_samples = trial.nb_val_samples\n",
    "        elif (data_type == \"train\"):\n",
    "            proc = [DataProcedure.from_json(trial.archive_dir, t) for t in trial.train_procedure]\n",
    "            num_samples = trial.samples_per_epoch\n",
    "        else:\n",
    "            raise ValueError(\"data_type must be either val or train but got %r\" % data_type)\n",
    "        model = None\n",
    "        if (return_prediction):\n",
    "            model = trial.compile(loadweights=True, custom_objects=custom_objects)\n",
    "        DataIterator.__init__(self, proc, num_samples=num_samples, return_X=return_X, return_Y=return_Y,\n",
    "                              accumilate=accumilate, prediction_model=model)\n",
    "def getError(model, data=None, num_samples=None,custom_objects={}, ignoreAssert=False):\n",
    "    '''\n",
    "    Finds the standard error of the mean for the validation accuracy of a model on a dataset or a trial.\n",
    "    #Arguements:\n",
    "            model -- The model being evaluated, or a KerasTrial containing a valid model.\n",
    "            data  -- A generator, or DataProcedure containing the data to be run through the model. If a generator or DataProcedure\n",
    "                     containing a generator is given the num_samples must be set. If model is a KerasTrial this can be set to None, and the validation\n",
    "                     set will be found from the archive (or computed) and used in place of data.\n",
    "            num_samples -- The number of samples to evaluate the error on.\n",
    "            custom_objects -- A dictionary keyed by names containing the classes of any model components not used in the standard Keras library.\n",
    "            ignoreAssert -- If True ignore assertion errors. This code tests to see that the validation accuracy it computes is similar to the one computed by keras.\n",
    "                            If this is not the case then an error will be raised.\n",
    "    #Returns:\n",
    "        The standard error of the validation accuracy\n",
    "    '''\n",
    "    isTrial = False\n",
    "    if(isinstance(model, KerasTrial)):\n",
    "        trial = model\n",
    "        model = trial.compile(loadweights=True,custom_objects=custom_objects)\n",
    "        isTrial = True\n",
    "\n",
    "    def accum(X,Y):\n",
    "        return model.test_on_batch(X,Y)\n",
    "\n",
    "    if (isTrial):\n",
    "        dItr = TrialIterator(trial, return_X=False, return_Y=False, return_prediction=False, accumilate=accum)\n",
    "    else:\n",
    "        dItr = DataIterator(data, return_X=False, return_Y=False,\n",
    "                            num_samples=num_samples, accumilate=accum)\n",
    "\n",
    "    batch_metrics = dItr.asList()\n",
    "\n",
    "    batch_metrics = np.array(batch_metrics)\n",
    "    avg = np.mean(batch_metrics, axis=0, dtype='float64')\n",
    "    sem = np.std(batch_metrics, axis=0, dtype='float64')/np.sqrt(i)\n",
    "    if(not ignoreAssert and trial.get_from_record(\"val_acc\") != None):\n",
    "        np.testing.assert_almost_equal(trial.get_from_record(\"val_acc\"), avg[1], decimal=3)\n",
    "    else:\n",
    "        trial.to_record({\"val_acc_\" : avg[1]})\n",
    "    trial.to_record({\"val_acc_error\" : sem[1]})\n",
    "    return trial.get_from_record(\"val_acc_error\")\n",
    "\n",
    "trial = trials[0]\n",
    "print(getError(trial,custom_objects={\"Slice\": Slice, \"Lorentz\": Lorentz}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "\n",
    "trial = trials[0]\n",
    "\n",
    "observable_ordering=['E/c', 'Px', 'Py', 'Pz', 'PT_ET','Eta', 'Phi', 'Charge', 'X', 'Y', 'Z', \n",
    "                     'Dxy', 'Ehad', 'Eem', 'MuIso', 'EleIso', 'ChHadIso','NeuHadIso','GammaIso']\n",
    "object_ordering=[\"Electron\", \"MuonTight\", \"MissingET\",\"EFlowPhoton\", \"EFlowNeutralHadron\", \"EFlowTrack\"]\n",
    "\n",
    "#=d = accVsEventChar(trial, None, np.sum, \"PT_ET\", objects=[\"EFlowPhoton\",\"EFlowNeutralHadron\",\"EFlowTrack\"], \n",
    "#                       observable_ordering=observable_ordering,object_ordering=object_ordering,\n",
    "#                       bins=20,custom_objects={\"Slice\": Slice, \"Lorentz\": Lorentz},equalBins=False)\n",
    "d = accVsEventChar(trial, None, np.sum, \"PT_ET\", objects=[\"EFlowPhoton\",\"EFlowNeutralHadron\",\"EFlowTrack\"],\n",
    "                       observable_ordering=observable_ordering,object_ordering=object_ordering,\n",
    "                       bins=20,custom_objects={\"Slice\": Slice, \"Lorentz\": Lorentz},equalBins=False, plot=True)\n",
    "#assert set([t for t in d.items()]) == set([t for t in d2.items()])\n",
    "#def plot_ROC(trial):\n",
    "#    X,Y = \n",
    "#    sklearn.metrics.roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = findWithMetrics(trials, {\"useObjTypeColumn\" : True})\n",
    "print_by_labels(trials, 4)\n",
    "\n",
    "#plot_history([(\"Fully connected:\", trials[0].get_history())], plotLoss=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = findWithMetrics(trials, {\"labels\" : [u'ttbar', u'wjet', u'qcd'], 'sort_on' : \"Phi\"})\n",
    "t[0].summary(showCompilation=True, showFit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotEverything(trials)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi = findWithMetrics(trials,{\"sort_on\" : \"Phi\"})\n",
    "eta = findWithMetrics(trials,{\"sort_on\" : \"Eta\"})\n",
    "PT = findWithMetrics(trials,{\"sort_on\" : \"PT_ET\"})\n",
    "sortOnMetric(phi, \"labels\")\n",
    "sortOnMetric(eta, \"labels\")\n",
    "sortOnMetric(PT, \"labels\")\n",
    "labelGroups = zip(phi,eta,PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = [(0,0,1.0),(.25,.75,.25), (1,.65,0)]\n",
    "names = [\"Phi\", \"Eta\",\"PT\"]\n",
    "lims = [[.7,.91], [.8,1.0],  [.8,1.0],  [.4,.82]]\n",
    "for j , tup in enumerate(labelGroups):\n",
    "    plots = []\n",
    "    for i, b in enumerate(tup):\n",
    "        labels = b.get_from_record(\"labels\")\n",
    "        if(labels == None): labels = b.get_from_record(\"lables\")\n",
    "        title = str(tuple([str(x) for x in labels])) if(labels != None) else \"Cannot Find Labels\"\n",
    "        title = title + \" Accuracy vs Epoch\"\n",
    "        name = names[i]\n",
    "        model = b.get_model(custom_objects={\"Slice\":Slice, \"Lorentz\" : Lorentz})\n",
    "        history = b.get_history()\n",
    "        color = colors[i]\n",
    "        plots.append((name, history, color))\n",
    "    plot_history(plots, plotLoss=False, title=title, acclims=lims[j])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.zeros(( len(labelGroups[0]),len(labelGroups) ) ).tolist()\n",
    "print(data)\n",
    "columns = [None] * len(labelGroups)\n",
    "rows = [\" \"+ n + \" \" for n in names]\n",
    "\n",
    "for j , tup in enumerate(labelGroups):\n",
    "    for i, b in enumerate(tup):\n",
    "        labels = b.get_from_record(\"labels\")\n",
    "        columns[j] = str(tuple([str(x) for x in labels]))\n",
    "        error = getError(b,custom_objects={\"Slice\":Slice, \"Lorentz\" : Lorentz}, ignoreAssert=True)\n",
    "        d = \"%.5f %s %.5f\" % (b.get_from_record(\"val_acc\"),unichr(177), error)\n",
    "        data[i][j] = d\n",
    "        \n",
    "        \n",
    "#print(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotTable(rows, columns, data,scale=2, title=\"Validation Accuracy for LSTM Trials by Classification and Sorting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getTrialBins(trial, bins=20):\n",
    "    trial.summary()\n",
    "    d = accVsEventChar(trial, None, np.sum, \"PT_ET\", [\"EFlowPhoton\",\"EFlowNeutralHadron\",\"EFlowTrack\"],\n",
    "                       bins=bins,custom_objects={\"Slice\": Slice, \"Lorentz\": Lorentz},equalBins=False)\n",
    "    #plotBins(d,title='Accuracy vs Sum of PF Candidate PT', xlabel=\"PT GeV\", ylabel='Accuracy', color=(0.553,0.188,0.38))\n",
    "    return d\n",
    "eta_bins = [getTrialBins(t,40) for t in eta]\n",
    "phi_bins = [getTrialBins(t,40) for t in phi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = [(0,0,1.0),(.25,.75,.25), (1,0,0), (1,.65,0)]\n",
    "lables = [trial.get_from_record(\"labels\") for trial in eta]\n",
    "plotBins(eta_bins,mode=\"scatter\",title='Eta-LSTM: Accuracy vs Sum of PF Candidate PT',binLabels=lables, xlabel=\"PT GeV\", ylabel='Accuracy',\n",
    "         legendTitle=\"Classification\",colors=colors, alpha=.2, ylim=(0.75, 1.025), xlim=(0,3000))\n",
    "\n",
    "lables = [trial.get_from_record(\"labels\") for trial in phi]\n",
    "plotBins(phi_bins,mode=\"scatter\",title='Phi-LSTM: Accuracy vs Sum of PF Candidate PT',binLabels=lables, xlabel=\"PT GeV\", ylabel='Accuracy',\n",
    "         legendTitle=\"Classification\",legendBelow=True,colors=colors, alpha=.4, ylim=(0.75, 1.025), xlim=(0,3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
