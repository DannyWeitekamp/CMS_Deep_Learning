{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IO Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys, types\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import itertools\n",
    "from six import string_types,reraise\n",
    "os.environ.update\n",
    "\n",
    "%matplotlib inline\n",
    "if __package__ is None:\n",
    "    import sys, os\n",
    "    #sys.path.append(os.path.realpath(\"/data/shared/Software/CMS_Deep_Learning\"))\n",
    "    sys.path.append(os.path.realpath(\"/home/dweitekamp/CMS_Deep_Learning/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from CMS_Deep_Learning.io import repr_structure, retrieve_data, nb_samples_from_h5, \\\n",
    "                    gen_from_data, simple_grab, restructure, flatten, assert_list, DataIterator\n",
    "import glob\n",
    "lcd_dir = '/bigdata/shared/LCD/kaustuv1993/NewLCD/GammaEscan_1_MERGED'\n",
    "dat_file = lcd_dir + '/GammaEscan_1_10.h5'\n",
    "example_dir = '/bigdata/shared/Delphes/postproc_ex/'\n",
    "ex_subset = glob.glob(example_dir + \"/val/*.h5\")[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab data from a single file with [retrieve_data]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<(9902, 5, 5, 60)>,<(9902, 25, 25, 25)>],<(9902, 1, 5)>]\n",
      "[<(9902, 5, 5, 60)>,<(9902, 1, 5)>]\n",
      "<(9902, 25, 25, 25)>\n"
     ]
    }
   ],
   "source": [
    "file_dat_v1 = repr_structure(retrieve_data(dat_file,[['HCAL', 'ECAL'], 'target']))\n",
    "file_dat_v2 = repr_structure(retrieve_data(dat_file,['HCAL', 'target']))\n",
    "file_dat_v3 = repr_structure(retrieve_data(dat_file, 'ECAL'))\n",
    "print(repr_structure(file_dat_v1))\n",
    "print(repr_structure(file_dat_v2))\n",
    "print(repr_structure(file_dat_v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we need the length of as single file (i.e number of samples) of the file we can use [retrieve_data]() with just_length=True or [nb_samples_from_h5]() which also works with pandas tables. Also see [size_from_meta](), which caches the sizes of files for quicker reads on big jobs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9902,9902],9902]\n",
      "9902\n"
     ]
    }
   ],
   "source": [
    "file_size_v1 = repr_structure(retrieve_data(dat_file,[['HCAL', 'ECAL'], 'target'],just_length=True))\n",
    "file_size_v2 = nb_samples_from_h5(dat_file)\n",
    "\n",
    "print(file_size_v1)\n",
    "print(file_size_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a generator with [gen_from_data]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<(100, 25, 25, 25)>,<(100, 5, 5, 60)>],<(100, 1, 5)>]\n",
      "[<(100, 25, 25, 25)>,<(100, 1, 5)>]\n",
      "<(100, 25, 25, 25)>\n"
     ]
    }
   ],
   "source": [
    "gen1 = gen_from_data(lcd_dir, batch_size=100, data_keys=[ [\"ECAL\",\"HCAL\"], 'target'])\n",
    "gen2 = gen_from_data(lcd_dir, batch_size=100, data_keys=[ \"ECAL\", 'target'])\n",
    "gen3 = gen_from_data(lcd_dir, batch_size=100, data_keys=\"ECAL\")\n",
    "print(repr_structure(next(gen1)))\n",
    "print(repr_structure(next(gen2)))\n",
    "print(repr_structure(next(gen3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use [simple_grab]() for grabbing predictions or data for making plots. Remember to pass any information that you need, for example if you need predictions then you need to pass the data, model, and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:05:00.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((37500, 3), (37500, 3))\n",
      "(37500, 3)\n",
      "((37500, 801, 19), (37500, 3))\n"
     ]
    }
   ],
   "source": [
    "Y,predictions = simple_grab(['Y','predictions'], data=example_dir +\"/val\",\n",
    "            model=example_dir +\"model.json\",weights=example_dir+\"weights.h5\",\n",
    "           input_keys='Particles',label_keys='Labels')\n",
    "print(Y.shape, predictions.shape)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "Y = simple_grab('Y', data=example_dir +\"/val\",\n",
    "           input_keys='Particles',label_keys='Labels')\n",
    "print(Y.shape)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "X,Y = simple_grab(['X','Y'], data=example_dir +\"/val\",\n",
    "           input_keys='Particles',label_keys='Labels')\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "#--------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This time we output with a nested structure and give it a list of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/bigdata/shared/Delphes/postproc_ex//val/000.h5', '/bigdata/shared/Delphes/postproc_ex//val/001.h5']\n",
      "[[<(15000, 801, 19)>,<(15000, 3)>],<(15000, 3)>]\n",
      "((15000, 801, 19), (15000, 3))\n"
     ]
    }
   ],
   "source": [
    "print(ex_subset)\n",
    "grabbed_complex = simple_grab([['X','Y'],'predictions'], data=ex_subset,\n",
    "            model=example_dir +\"model.json\",weights=example_dir+\"weights.h5\",\n",
    "           input_keys='Particles',label_keys='Labels')\n",
    "print(repr_structure(grabbed_complex))\n",
    "\n",
    "X,Y = grabbed_complex[0][0],grabbed_complex[0][1]\n",
    "X,Y = simple_grab(['X','Y'], X=X,Y=Y)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And finally we can use [flatten]() and [restructure]() if we would like to change our nesting structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "[0, 1, [2, 3], [4, 0], [1], 2]\n",
      "[[1, 2], 3]\n"
     ]
    }
   ],
   "source": [
    "print(flatten([0,[1,2,3],[4,[5]]]))\n",
    "print(restructure([0,1,2,3,4,0,1,2,3], ['B','F',['d','f'],['A','B'], ['C'],'D']))\n",
    "print(restructure([1,2,3], [['HCAL', 'ECAL'], 'HCAL']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
